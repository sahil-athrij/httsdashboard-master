{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8e39d2cb3ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdateutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACILib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytz'"
     ]
    }
   ],
   "source": [
    "import os , configparser, re, os, datetime, dateutil, pytz, copy\n",
    "from dateutil import parser\n",
    "import ACILib\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./tacconfig.ini')\n",
    "    \n",
    "shift = 'apjc'\n",
    "tech_strip= 'aci'\n",
    "\n",
    "date = '2020-09-02'\n",
    "date = datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "shift_hour,gmt_hour = ACILib.GetShiftHour(date,shift=shift)\n",
    "shift_start_hour,shift_end_hour = shift_hour[0],shift_hour[1]\n",
    "InterestQueueName = config[shift]['_'.join(['queuename',tech_strip.upper()])]\n",
    "InterestQueueName = InterestQueueName.split(',')\n",
    "\n",
    "logfile = '/home/jovyan/HTTSDashboard/logs/RabbitMQ_ACI_Event.log'\n",
    "logfile = '/home/jovyan/HTTSDashboard/logs/RabbitMQ_SV_Event.log'\n",
    "\n",
    "event_path = config[shift]['_'.join(['eventpath',tech_strip.upper()])]\n",
    "logfilename = config[shift]['_'.join(['logfilename',tech_strip.upper()])]\n",
    "InterestQueueName = config[shift]['_'.join(['queuename',tech_strip.upper()])]\n",
    "InterestQueueName = InterestQueueName.split(',')\n",
    "        \n",
    "logfiletime = os.path.getmtime(logfile)\n",
    "logfiledatetime = datetime.datetime.fromtimestamp(logfiletime)\n",
    "logfiledatetime,shift_start_hour,shift_end_hour,InterestQueueName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sourcefile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-21ce9f8cc3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcurrent_container_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjupyter_container_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msourcefiletime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourcefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msourcefiledatetime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourcefiletime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msourcefileformattime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msourcefiledatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sourcefile' is not defined"
     ]
    }
   ],
   "source": [
    "#It was exected in the jupyter notebook container , path is different from flask container.\n",
    "\n",
    "\n",
    "#current_hour = datetime.datetime.now().hour\n",
    "#if current_hour >= 6:\n",
    "#    exit()\n",
    "\n",
    "jupyter_container_path = '/home/jovyan'\n",
    "flask_container_path = ''\n",
    "current_container_path = jupyter_container_path\n",
    "\n",
    "sourcefiletime = os.path.getmtime(sourcefile)\n",
    "sourcefiledatetime = datetime.datetime.fromtimestamp(sourcefiletime)\n",
    "sourcefileformattime = sourcefiledatetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "commentfile = current_container_path + '/HTTSDashboard/logs/ACI/data/comment.txt'\n",
    "casestatsdir = current_container_path + '/HTTSDashboard/logs/ACI/data/'\n",
    "engrstatsdir = current_container_path + '/HTTSDashboard/logs/ACI/data/'\n",
    "dailyreportfiledir = current_container_path + '/HTTSDashboard/logs/ACI/data/report/'\n",
    "dailyreportfiledir = current_container_path + '/HTTSDashboard/logs/TAC/SEC/data/report/'\n",
    "dailyreportfilename = date+'.txt'\n",
    "dailyreportstring = \"\"\n",
    "\n",
    "SYDEngrList = ['tonzeng','minkwong','siddhp','wilchong','debabbar','lindawa','junwa','annelso2','ikarvoun']\n",
    "BGLEngrList = ['deepaky','knagavol','jawalia','prpratee','maveer','raghb','roagraw2','shparanj','vkalmath']\n",
    "BGLOtherEngrList = ['anirukas','reperuma','deepakba','bharatkc','kdoodi']\n",
    "SYDOtherEngrList = ['zdazhi','zmeng']\n",
    "CSSEngrList = []\n",
    "OnShiftEngrList = []\n",
    "\n",
    "#ACI_InterestQueueName = ['WW-ACI-Solutions','CX-APJC-BLR-ACI-SSPT','CX-APJC-SYD-ACI-SSPT','WW-Rakuten-ACI']\n",
    "#SV_InterestQueueName = ['WW-SV','WW-STORAGE']\n",
    "#InterestQueueName = ACI_InterestQueueName\n",
    "\n",
    "CaseQty = {'CX-APJC-BLR-ACI-SSPT':0,\n",
    "           'WW-ACI-Solutions':0,\n",
    "           'CX-APJC-SYD-ACI-SSPT':0,\n",
    "           'WW-Rakuten-ACI':0,\n",
    "           'FTS':0,'UC':0}\n",
    "CaseTakenDic = {}\n",
    "CaseTakenDicInclNo = {'SYD':{},'SYD_Other':{},'BGL':{},'BGL_Other':{}}\n",
    "CaseTakenByEngrDic = {}\n",
    "CaseStatsDic = {\"SydQueueVol\":0,\"BGLQueueVol\":0,\n",
    "                \"SydTakenVol\":0,\"BGLTakenVol\":0,\n",
    "                'FTSCaseVol':0,'UCCaseVol':0,\n",
    "                \"SydQueueVolByPri\":[0,0,0,0,0,0],\"BGLQueueVolByPri\":[0,0,0,0,0,0], #0 FTS #1,2,3,4 Priority #5 Urgent Collab\n",
    "                \"SydTakenVolByPri\":[0,0,0,0,0,0],\"BGLTakenVolByPri\":[0,0,0,0,0,0], #0 FTS #1,2,3,4 Priority #5 Urgent Collab\n",
    "                \"SydOnShiftEngr\":1,\"BGLOnShiftEngr\":1,\n",
    "                \"SydOnShiftEngrTakenVol\":0,\"BGLOnShiftEngrTakenVol\":1,\n",
    "                \"SYDHelper\":0,\"BGLHelper\":0,\n",
    "                }\n",
    "\n",
    "with open(logfile) as f:\n",
    "    allevents = f.read()\n",
    "f.close()\n",
    "\n",
    "allevents = allevents.split(\"\\n\")\n",
    "allevents[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RabbitMQ_SV_Event.log-2020-06-24 05:57:54,504-INFO-MQToRedis:689318518 3 Case_InQueue HTTS-APAC-ENT1 Proactive case for UCS <ucsvsibeld010.svr.us.jpmchase.net> firmware upgrade to 3.2.3 j at 2020-06-24 05:53:21',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:26,530-INFO-MQToRedis:689353475 3 Case_InQueue GCE-APT-SV Blade server on chassis has failed to find its boot media after restart at 2020-06-24 05:56:36',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:28,974-INFO-MQToRedis:689353475 3 Case_InQueue GCE-APT-SV Blade server on chassis has failed to find its boot media after restart at 2020-06-24 05:57:04',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:29,886-INFO-MQToRedis:689353409 3 Case_InQueue GCE-APT-SV Call Home: Device reported Environment error(s). [Connected via Intersight] at 2020-06-24 05:39:35',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:32,516-INFO-MQToRedis:689353475 3 Case_InQueue GCE-APT-SV Blade server on chassis has failed to find its boot media after restart at 2020-06-24 05:56:38',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:33,612-INFO-MQToRedis:689331025 3 Case_Accepted Power outage and all servers in chassis are down taken by nagordon APT-SV at 2020-06-24 05:58:12',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:33,678-INFO-MQToRedis:689331025 3 Case_Accepted Power outage and all servers in chassis are down taken by nagordon APT-SV at 2020-06-24 05:58:12',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:33,965-INFO-MQToRedis:689353409 3 Case_Accepted Call Home: Device reported Environment error(s). [Connected via Intersight] taken by vischock GCE-APAC-SV at 2020-06-24 05:58:41',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:33,994-INFO-MQToRedis:689353409 3 Case_Accepted Call Home: Device reported Environment error(s). [Connected via Intersight] taken by vischock GCE-APAC-SV at 2020-06-24 05:58:41',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:39,593-INFO-MQToRedis:689318518 3 Case_Accepted Proactive case for UCS <ucsvsibeld010.svr.us.jpmchase.net> firmware upgrade to 3.2.3 j taken by afaizur HTTS-APAC-ENT1 at 2020-06-24 05:59:22',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:39,694-INFO-MQToRedis:689318518 3 Case_Accepted Proactive case for UCS <ucsvsibeld010.svr.us.jpmchase.net> firmware upgrade to 3.2.3 j taken by afaizur HTTS-APAC-ENT1 at 2020-06-24 05:59:22',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:43,045-INFO-MQToRedis:689353487 3 Case_InQueue WW-SV [Meralco] Dimm error at 2020-06-24 05:58:42',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:00:43,325-INFO-MQToRedis:689353487 3 Case_InQueue WW-SV [Meralco] Dimm error at 2020-06-24 05:58:44',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:01:47,699-INFO-MQToRedis:689353487 3 Case_InQueue WW-SV [Meralco] Dimm error at 2020-06-24 05:58:53',\n",
       " \"RabbitMQ_SV_Event.log-2020-06-24 06:01:48,256-INFO-MQToRedis:689344343 3 Case_InQueue GCE-APT-SV UCSB-B200-M5-U // IOM Modules. It's not being detected. at 2020-06-24 05:56:35\",\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:01:52,567-INFO-MQToRedis:689353475 3 Case_InQueue GCE-APT-SV Blade server on chassis has failed to find its boot media after restart at 2020-06-24 05:56:49',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:01:53,623-INFO-MQToRedis:689353475 3 Case_InQueue GCE-APT-SV Blade server on chassis has failed to find its boot media after restart at 2020-06-24 05:57:11',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 06:02:21,753-INFO-MQToRedis:689353409 3 Case_InQueue GCE-APT-SV Call Home: Device reported Environment error(s). [Connected via Intersight] at 2020-06-24 05:56:49',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 09:16:14,711-INFO-MQToRedis:689352335 4 Case_InQueue WW-SV UCSC-C220-M5SX Authentication at 2020-06-24 01:17:19',\n",
       " 'RabbitMQ_SV_Event.log-2020-06-24 09:16:37,368-INFO-MQToRedis:689352335 4 Case_Accepted UCSC-C220-M5SX Authentication taken by davdodd APT-SV at 2020-06-24 01:51:49']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetRawEventsFromDate(allevents,date='2020-02-27',shift_start_hour=0,shift_end_hour=6,debug=False):\n",
    "    \n",
    "    date = date\n",
    "    shift_start_hour = shift_start_hour\n",
    "    shift_end_hour = shift_end_hour\n",
    "    allevents_in_date = []\n",
    "    \n",
    "    CaseMatchLine_Reg = re.compile(r'.*?MQToRedis:\\d{9}\\s\\d\\s.*at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    \n",
    "    for line in allevents[:]:\n",
    "        if date not in line:\n",
    "            continue\n",
    "        if re.search(CaseMatchLine_Reg,line):\n",
    "            #print(\"Matching line {}\".format(line))\n",
    "            line_datetime = parser.parse(re.search(CaseMatchLine_Reg,line).group(1))\n",
    "            #dispatched case might dispatch to today while not take into account\n",
    "            \n",
    "            if line_datetime.strftime(\"%Y-%m-%d\") != date:\n",
    "                #print(\"{} - {}\".format(line_datetime.strftime(\"%Y-%m-%d\"),date))\n",
    "                continue\n",
    "            if line_datetime.hour >= shift_start_hour and line_datetime.hour < shift_end_hour:\n",
    "                allevents_in_date.append(line)\n",
    "    return allevents_in_date\n",
    "\n",
    "allevents_in_date = GetRawEventsFromDate(allevents,shift_start_hour=shift_start_hour,shift_end_hour=shift_end_hour,date=date)\n",
    "allevents_in_date[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WW-SV', 'WW-STORAGE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['689353213-~3-~WW-SV-~2020-06-24 04:53:24',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:22:41',\n",
       " '689352335-~4-~WW-SV-~2020-06-24 01:17:19',\n",
       " '689352637-~3-~WW-STORAGE-~2020-06-24 02:20:43',\n",
       " '689352639-~3-~WW-STORAGE-~2020-06-24 02:21:07',\n",
       " '689212357-~3-~WW-SV-~2020-06-24 02:30:24',\n",
       " '689352360-~3-~WW-STORAGE-~2020-06-24 01:09:28',\n",
       " '689353452-~4-~WW-SV-~2020-06-24 05:51:11',\n",
       " '689353487-~3-~WW-SV-~2020-06-24 05:58:53',\n",
       " '689353157-~3-~WW-SV-~2020-06-24 04:39:23',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:06:31',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:22:28',\n",
       " '689352150-~3-~WW-SV-~2020-06-24 00:02:17',\n",
       " '689352150-~3-~WW-SV-~2020-06-24 00:02:39',\n",
       " '689212357-~3-~WW-SV-~2020-06-24 02:30:17',\n",
       " '689352417-~3-~WW-SV-~2020-06-24 01:25:48',\n",
       " '689352360-~3-~WW-STORAGE-~2020-06-24 01:09:51',\n",
       " '689352360-~3-~WW-STORAGE-~2020-06-24 01:09:57',\n",
       " '689352417-~3-~WW-SV-~2020-06-24 01:25:59',\n",
       " '689352135-~3-~WW-STORAGE-~2020-06-24 00:01:24',\n",
       " '689353157-~3-~WW-SV-~2020-06-24 04:39:13',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:52:41',\n",
       " '689352150-~3-~WW-SV-~2020-06-24 00:04:24',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:35:12',\n",
       " '689352637-~3-~WW-STORAGE-~2020-06-24 02:20:44',\n",
       " '689353213-~3-~WW-SV-~2020-06-24 04:53:35',\n",
       " '689353487-~3-~WW-SV-~2020-06-24 05:58:42',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:35:07',\n",
       " '689352135-~3-~WW-STORAGE-~2020-06-24 00:06:27',\n",
       " '689352368-~3-~WW-STORAGE-~2020-06-24 01:45:44',\n",
       " '689352639-~3-~WW-STORAGE-~2020-06-24 02:20:59',\n",
       " '689264575-~3-~WW-STORAGE-~2020-06-24 03:56:29',\n",
       " '689331025-~3-~WW-SV-~2020-06-24 05:39:39',\n",
       " '689347849-~3-~WW-SV-~2020-06-24 00:11:20',\n",
       " '689353213-~3-~WW-SV-~2020-06-24 04:53:26',\n",
       " '689351184-~3-~WW-SV-~2020-06-24 03:00:16',\n",
       " '689352135-~3-~WW-STORAGE-~2020-06-24 00:01:40',\n",
       " '689352417-~3-~WW-SV-~2020-06-24 01:25:47',\n",
       " '689347849-~3-~WW-SV-~2020-06-24 00:41:39',\n",
       " '689331025-~3-~WW-SV-~2020-06-24 05:39:32',\n",
       " '689352368-~3-~WW-STORAGE-~2020-06-24 01:16:35',\n",
       " '689353487-~3-~WW-SV-~2020-06-24 05:58:44',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:06:43',\n",
       " '689347849-~3-~WW-SV-~2020-06-24 00:11:40',\n",
       " '689352360-~3-~WW-STORAGE-~2020-06-24 01:09:36',\n",
       " '689353157-~3-~WW-SV-~2020-06-24 04:39:15',\n",
       " '689353452-~4-~WW-SV-~2020-06-24 05:51:09',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:22:30',\n",
       " '689264575-~2-~WW-STORAGE-~2020-06-24 03:56:49',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:06:33',\n",
       " '689353452-~4-~WW-SV-~2020-06-24 05:51:19',\n",
       " '689333106-~2-~FTS-~2020-06-24 00:03:32',\n",
       " '689352110-~1-~FTS-~2020-06-24 00:10:48',\n",
       " '689352110-~1-~UC-~2020-06-24 00:03:20',\n",
       " '689319966-~3-~UC-~2020-06-24 00:04:43',\n",
       " '689352699-~3-~UC-~2020-06-24 03:38:36',\n",
       " '689272890-~3-~UC-~2020-06-24 03:43:07',\n",
       " '689352699-~3-~UC-~2020-06-24 03:41:35',\n",
       " '689133838-~1-~UC-~2020-06-24 04:55:02']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FindInQueueEvent(CaseEventsList,InterestQueueName=[],shift_start_hour=0,shift_end_hour=6,debug=False):\n",
    "    \n",
    "    InterestQueueName = InterestQueueName\n",
    "    \n",
    "    #1 Case Number #2 Case Priority #3 Case Qeueue #4 Event Timestamp\n",
    "    InQueue_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d).*Case_InQueue\\s(.+?)\\s.*at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    #1 Case Number #2 Case Priority #3 Event Timestamp\n",
    "    FTS_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d).*FTS_InQueue\\s.*at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    UC_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d).*UC_InQueue.*at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    \n",
    "    CaseInQueueRawList = []\n",
    "    FTSInQueueRawList = []\n",
    "    UCInQueueRawList = []\n",
    "    \n",
    "    for line in CaseEventsList:\n",
    "        if 'Case_InQueue' in line:\n",
    "            #break\n",
    "            if re.search(InQueue_Reg,line):\n",
    "                #print(line)\n",
    "                CaseInQueueRawList.append(re.search(InQueue_Reg,line).group(1)+\"-~\"+\n",
    "                              re.search(InQueue_Reg,line).group(2)+\"-~\"+\n",
    "                              re.search(InQueue_Reg,line).group(3)+\"-~\"+\n",
    "                              re.search(InQueue_Reg,line).group(4))\n",
    "    \n",
    "    #CaseInQueueRawList = [re.search(InQueue_Reg,line).group(1)+\"-~\"+\n",
    "    #                      re.search(InQueue_Reg,line).group(2)+\"-~\"+\n",
    "    #                      re.search(InQueue_Reg,line).group(3)+\"-~\"+\n",
    "    #                      re.search(InQueue_Reg,line).group(4) \n",
    "    #                      for line in CaseEventsList if 'Case_InQueue' in line]\n",
    "\n",
    "    for line in CaseEventsList:\n",
    "        if 'FTS_InQueue' in line:\n",
    "            #print(line)\n",
    "            if re.search(FTS_Reg,line):\n",
    "                #print(\"Add FTS \".format(line))\n",
    "                FTSInQueueRawList.append(re.search(FTS_Reg,line).group(1)+\"-~\"+\n",
    "                              re.search(FTS_Reg,line).group(2)+\"-~FTS-~\"+\n",
    "                              re.search(FTS_Reg,line).group(3))\n",
    "                \n",
    "    #FTSInQueueRawList = [re.search(FTS_Reg,line).group(1)+\"-~\"+\n",
    "    #                     re.search(FTS_Reg,line).group(2)+\"-~FTS-~\"+\n",
    "    #                     re.search(FTS_Reg,line).group(3) \n",
    "    #                     for line in CaseEventsList if 'FTS_InQueue' in line]\n",
    "    \n",
    "    UCInQueueRawList = [re.search(UC_Reg,line).group(1)+\"-~\"+\n",
    "                         re.search(UC_Reg,line).group(2)+\"-~UC-~\"+\n",
    "                         re.search(UC_Reg,line).group(3) \n",
    "                         for line in CaseEventsList if 'UC_InQueue' in line]\n",
    "    \n",
    "    ###### if the case case in before shift start and event in the shift start, it will still be recorded, need to remove ######\n",
    "    #2020-03-06 01:00:19,511-INFO-MQToRedis:688593987 3 Case_InQueue WW-ACI-Solutions L2NodeAuthPolicy at 2020-03-06 00:58:47\n",
    "    #Example is as above\n",
    "    CaseInQueueRawRemoveBeforeShiftEventList = []\n",
    "    for caseline in CaseInQueueRawList:\n",
    "        #print(caseline)\n",
    "        caseno, priority, queue, casetime = caseline.split(\"-~\")\n",
    "        case_datetime = parser.parse(casetime)\n",
    "        if case_datetime.hour >= shift_start_hour and case_datetime.hour < shift_end_hour:\n",
    "            CaseInQueueRawRemoveBeforeShiftEventList.append(caseline)\n",
    "    CaseInQueueRawList = CaseInQueueRawRemoveBeforeShiftEventList    \n",
    "    \n",
    "    if debug:\n",
    "        print(\"Original CaseInQueue List length {}\".format(len(CaseInQueueRawList)))\n",
    "        print(\"Original FTSInQueue List length {}\".format(len(FTSInQueueRawList)))\n",
    "        print(\"Original UCInQueue List length {}\".format(len(UCInQueueRawList)))\n",
    "        \n",
    "    NotInterestQueueIndexList = [index for index,case in enumerate(CaseInQueueRawList) if case.split(\"-~\")[2] not in InterestQueueName]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Not Interest Queue Index list {}\".format(NotInterestQueueIndexList))\n",
    "    \n",
    "    CaseInQueueRemoveNotInterestQueueExtList = [line for line in CaseInQueueRawList]\n",
    "    \n",
    "    for index in NotInterestQueueIndexList[::-1]:\n",
    "        #print(\"Pop not interest {} from list\".format(index))\n",
    "        CaseInQueueRemoveNotInterestQueueExtList.pop(index)\n",
    "    \n",
    "    CaseInQueueRemoveNotInterestQueueExtList = list(set(CaseInQueueRemoveNotInterestQueueExtList))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"After removing NotInterestQueue length {}\".format(len(CaseInQueueRemoveNotInterestQueueExtList)))\n",
    "        #for case in CaseInQueueRemoveNotInterestQueueExtList:\n",
    "        #    print(case)\n",
    "    \n",
    "    DuplicateInQueueIndexList = []\n",
    "    for index1, raw_case_line1 in enumerate(CaseInQueueRemoveNotInterestQueueExtList):\n",
    "        caseno1, priority1, queue1, time1 = raw_case_line1.split(\"-~\")\n",
    "        for index2, raw_case_line2 in enumerate(CaseInQueueRemoveNotInterestQueueExtList[index1+1:]):\n",
    "            caseno2, priority2, queue2, time2 = raw_case_line2.split(\"-~\")\n",
    "            #print(\"Comparing {} {} {} - {} {} {}\".format(caseno1,queue1,time1,caseno2,queue2,time2))\n",
    "            if caseno1 == caseno2 and time1 == time2:\n",
    "                #print(\"Found dupliate {} {}\".format(index1,index1+index2+1))\n",
    "                DuplicateInQueueIndexList.append(index1+index2+1)\n",
    "    if debug:\n",
    "        print(\"Duplicate Case Index list {}\".format(DuplicateInQueueIndexList))\n",
    "        for case in DuplicateInQueueIndexList:\n",
    "            print(case)\n",
    "            \n",
    "    CaseInQueueRemoveDupExtList = [line for line in CaseInQueueRemoveNotInterestQueueExtList]\n",
    "    for index in DuplicateInQueueIndexList[::-1]:\n",
    "        #print(\"Pop duplicate {} from list\".format(index))\n",
    "        CaseInQueueRemoveDupExtList.pop(index)\n",
    "    if debug:\n",
    "        print(\"After removing DuplicateCase length {}\".format(len(CaseInQueueRemoveDupExtList)))\n",
    "\n",
    "    return CaseInQueueRemoveDupExtList+FTSInQueueRawList+UCInQueueRawList\n",
    "\n",
    "print(InterestQueueName)\n",
    "InQueueEventList = FindInQueueEvent(allevents_in_date,InterestQueueName=InterestQueueName\n",
    "                                    ,shift_start_hour=shift_start_hour,shift_end_hour=shift_end_hour,debug=False)\n",
    "InQueueEventList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 7], 11.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def GetShiftHour(date='2020-04-05',shift='apjc'):\n",
    "    \n",
    "    date_datetime = parser.parse(date)\n",
    "\n",
    "    ShiftTime = {\n",
    "        '2020Summer':['2019-10-10','2020-03-28'],\n",
    "        '2020InterToWinter':['2020-03-29','2020-04-04'],\n",
    "        '2020Winter':['2020-04-05','2020-09-01'],\n",
    "        '2020InterToSummer':['2020-09-02','2020-10-03'],\n",
    "        '2020InterToSummer2':['2020-10-04','2020-10-25'],\n",
    "        '2020Summer':['2020-10-26','2021-03-27']\n",
    "    }\n",
    "    ShiftHour = {\n",
    "        'Summer':[1,7],\n",
    "        'InterToWinter':[0,6],\n",
    "        'Winter':[0,6],\n",
    "        'InterToSummer':[1,7],\n",
    "        'InterToSummer2':[2,8],\n",
    "        'Summer':[1,7]\n",
    "    }\n",
    "    \n",
    "    AESTorAEDT = {\n",
    "        '10':[\n",
    "            ['2020-04-04','2020-10-04'],\n",
    "            ['2021-04-05','2021-10-03']\n",
    "        ],\n",
    "        '11':[\n",
    "            ['2019-10-27','2020-04-04'],\n",
    "            ['2020-10-05','2021-04-04']\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    GMT_start = -1\n",
    "    ShiftStartHour = []\n",
    "    \n",
    "    for key,period in ShiftTime.items():\n",
    "        year,sfhit,start_datetime,end_datetime = key[:4],key[4:],parser.parse(period[0]),parser.parse(period[1])\n",
    "        #print(\"GetShiftHour - {} v.s. {} {} {} {}\".format(date, year,sfhit,period[0],period[1]))\n",
    "        if date_datetime >= start_datetime and date_datetime <= end_datetime:\n",
    "            ShiftStartHour = ShiftHour[key[4:]]  #[1, 7]\n",
    "            break\n",
    "    \n",
    "    if shift == 'apjc': \n",
    "        for gmthour,periodlist in AESTorAEDT.items():\n",
    "            for period in periodlist:\n",
    "                #print(period)\n",
    "                if date_datetime >= parser.parse(period[0]) and date_datetime <= parser.parse(period[1]):\n",
    "                    GMT_start = gmthour\n",
    "                    break\n",
    "    \n",
    "    if shift == 'emea':\n",
    "        GMT_start = 5.5\n",
    "        ShiftStartHour[0] = ShiftStartHour[0]+6\n",
    "        ShiftStartHour[1] = ShiftStartHour[1]+6\n",
    "\n",
    "    #print(\"ShiftStartHourInGMT {} StartGMT {}\".format(ShiftStartHour[0],GMT))\n",
    "    return ShiftStartHour, float(GMT_start)\n",
    "\n",
    "GetShiftHour(date='2020-11-20',shift='apjc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case UTC 2020-06-21 05:07:04\n",
      "isOnShift:Shift Hour [0, 6] [0, 6] Start GMT 10.0\n",
      "isOnShift:Hour 5 Minute 7\n",
      "isOnShift:IsOnShift 2020-06-21 05:07:04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('On', '2020-06-21 15:07:04')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isOnShift(timestamp,timezone='Australia/Sydney',shift='apjc',before_shift_hours_offset = 0, after_shift_hours_offset = 0, debug=False):\n",
    "    \n",
    "    '''\n",
    "    before_shift_hours_offset is the hours before shift if would like to be considered to be onshift, default is 0\n",
    "    after_shift_hours_offset is the hours after shift if would like to be considered to be onshift, default is 0\n",
    "    before_shift_hours_offset and after_shift_hours_offset is majorly used for dispatched case that dispatched one hour prior to shift would be considered.\n",
    "    \n",
    "    local = pytz.timezone (\"America/Los_Angeles\")\n",
    "    naive = datetime.datetime.strptime (\"2001-2-3 10:11:12\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    local_dt = local.localize(naive, is_dst=None)\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "    India Standard Time (Asia/Kolkata)\n",
    "    \n",
    "    Return Value:\n",
    "    ShiftInd: On or Off Shift\n",
    "    timstamp: Time in APJC is AEST/AEDT, Time in EMEA is IST \n",
    "    '''\n",
    "    \n",
    "    date, time = timestamp.split()\n",
    "    timezone = timezone.strip()\n",
    "    \n",
    "    local = pytz.timezone (timezone)\n",
    "    local_dt = local.localize(parser.parse(timestamp))\n",
    "    local_gmt_offset = local_dt.utcoffset().total_seconds()/60/60\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "    #print(\"InputTime:{} TimeZone:{} GMTOffset:{} UTCTime:{}\".format(\n",
    "    #    timestamp,timezone,local_gmt_offset,utc_dt.strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    utc_date = utc_dt.strftime(\"%Y-%m-%d\")\n",
    "    utc_time = utc_dt.strftime(\"%H:%M:%S\")\n",
    "    hour = utc_dt.hour\n",
    "    minute = utc_dt.minute\n",
    "    \n",
    "    shift_hour, GMT_start = GetShiftHour(date,shift)\n",
    "    orig_shift_hour = shift_hour.copy()\n",
    "    ###### If offset is considered, plus 24 as event might be at 23:00 - 24:00 the day before ######\n",
    "    if before_shift_hours_offset != 0 or after_shift_hours_offset != 0:\n",
    "        shift_hour[0] = shift_hour[0] + 24 - before_shift_hours_offset \n",
    "        shift_hour[1] = shift_hour[1] + after_shift_hours_offset + 24\n",
    "        if hour <= 7:\n",
    "            hour = hour + 24\n",
    "            \n",
    "    if debug:\n",
    "        print(\"Case UTC {} {}\".format(utc_date,utc_time))\n",
    "        print(\"isOnShift:Shift Hour {} {} Start GMT {}\".format(shift_hour,orig_shift_hour,GMT_start))\n",
    "        print(\"isOnShift:Hour {} Minute {}\".format(hour,minute))\n",
    "        \n",
    "    if hour >= shift_hour[0] and hour < shift_hour[1]:\n",
    "        if debug:\n",
    "            print(\"isOnShift:IsOnShift {}\".format(utc_date+' '+utc_time))\n",
    "        #return \"On\", (utc_dt + datetime.timedelta(hours=GMT_start+orig_shift_hour[0])).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return \"On\", (utc_dt + datetime.timedelta(hours=GMT_start)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"isOnShift:OffShift {}\".format(utc_date+' '+utc_time))\n",
    "        #return \"Off\", (utc_dt + datetime.timedelta(hours=(GMT_start+orig_shift_hour[0]))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return \"Off\", (utc_dt + datetime.timedelta(hours=(GMT_start))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "isOnShift(timestamp = '2020-06-21 05:07:04',timezone = 'GMT',shift='apjc',before_shift_hours_offset=0,debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689129699-~3-~2020-06-22 10:00:00-~Routing Configuration assistance on FTD',\n",
       " '689297421-~2-~2020-06-22 10:00:00-~[CAP Project} Proactive TAC for GITN SSL Enablement || BEMS require',\n",
       " '689333029-~3-~2020-06-22 12:30:00-~[Allianz Accenture] - ASA5515-K9 - Need support while IOS upgrade Firewall from 9.6(4)8 to 9.10.1.32',\n",
       " '689333117-~3-~2020-06-22 13:30:00-~ASA 5555 | Upgrade failed',\n",
       " '689333331-~3-~2020-06-22 14:00:00-~ASA FW unable to authentication from ISE',\n",
       " '689305070-~3-~2020-06-23 09:00:00-~[TEI] Appliance Keeps on Rebooting',\n",
       " '689341301-~3-~2020-06-23 10:01:00-~Skype for business: desktop sharing feature not working via Anyconnect',\n",
       " '689341423-~3-~2020-06-23 10:01:00-~Upgrade of ASA5585-SSP-60 from 5.4.0.9 to 6.1.0.7',\n",
       " '689257397-~3-~2020-06-23 10:30:00-~ASA Umbrella bypass traffic',\n",
       " '689289511-~3-~2020-06-23 10:30:00-~Anyconnect Client Upgrade for FQDN Slpit tunneling',\n",
       " '689322079-~3-~2020-06-23 10:40:00-~ISE 2.6 system not sending all required syslog messages to our syslog server.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Find Dispatch Event ######\n",
    "def FindDispatchEvent(CaseEventsList,debug=False):\n",
    "    \n",
    "    RawDispatchedEventList = []\n",
    "    \n",
    "    #Group 1.\t2932-2941\t689101876\n",
    "    #Group 2.\t2942-2943\t3\n",
    "    #Group 3.\t2964-3033\tAPIC Appliance || Maintenance window / Standby (Closed Wednesday 19) \n",
    "    #Group 4.\t3037-3056\t2020-05-17 01:00:00\n",
    "    #Group 5.\t3060-3066\t+05:30\n",
    "    #Group 6.\t3067-3102\t India Standard Time (Asia/Kolkata)\n",
    "    Dispatch_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d).*Case_Dispatched_Out\\s(.+?)To\\s\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})\\(GMT([+-]\\d{2}:\\d{2})\\)(.+)')\n",
    "    \n",
    "    for line in CaseEventsList:\n",
    "        if 'Case_Dispatched_Out' in line: \n",
    "            dispatch_line = re.search(Dispatch_Reg,line)\n",
    "            if dispatch_line:\n",
    "                caseno = dispatch_line.group(1)\n",
    "                severity = dispatch_line.group(2)\n",
    "                casetitle = dispatch_line.group(3).strip()\n",
    "                timestamp = dispatch_line.group(4)\n",
    "                #Two type of the timezone\n",
    "                #2020-02-09 00:30:00(GMT+03:00) Europe/Istanbul\n",
    "                #2020-01-08 08:30:00(GMT-06:00) Central Standard Time (America/Chicago)\n",
    "                if re.search(r'.+?\\((.+)\\)',dispatch_line.group(6)):\n",
    "                    timezone = re.search(r'.+?\\((.+)\\)',dispatch_line.group(6)).group(1)\n",
    "                else:\n",
    "                    timezone = dispatch_line.group(6)\n",
    "                ShiftInd , AESTorAEDTtimestamp = isOnShift(timestamp,timezone,before_shift_hours_offset=1)\n",
    "                if ShiftInd == \"On\":\n",
    "                    #print(\"OnShift {} {} {} {}\".format(caseno,timestamp,timezone,line))\n",
    "                    RawDispatchedEventList.append(\"-~\".join([caseno,severity,AESTorAEDTtimestamp,casetitle]))\n",
    "\n",
    "    ###### Remove multiple dispatched and keep only the last one ######\n",
    "    RemoveDuplicateDispatchedEventIdx = []\n",
    "    RemoveDuplicateDispatchedEventList = []\n",
    "    ExistingDispatchCaseDic = {} # {'Date':[CaseNoList]}\n",
    "    \n",
    "    for idx,line in enumerate(RawDispatchedEventList[::-1]):\n",
    "        caseno,casesev,casetime,casetitle = line.split('-~')\n",
    "        date = parser.parse(casetime).strftime(\"%Y-%m-%d\")\n",
    "        if date not in ExistingDispatchCaseDic.keys():\n",
    "            ExistingDispatchCaseDic[date] = []\n",
    "        if caseno not in ExistingDispatchCaseDic[date]:\n",
    "            ExistingDispatchCaseDic[date].append(caseno)\n",
    "        else:\n",
    "            RemoveDuplicateDispatchedEventIdx.append(len(RawDispatchedEventList)-idx-1)\n",
    "    \n",
    "    #print(set(RemoveDuplicateDispatchedEventIdx))\n",
    "    for idx,line in enumerate(RawDispatchedEventList):\n",
    "        if idx not in set(RemoveDuplicateDispatchedEventIdx):\n",
    "            RemoveDuplicateDispatchedEventList.append(line)\n",
    "    \n",
    "    ###### Sort the Dispatched Case ######\n",
    "    DispatchedEventRemainingIdx = [i for i in range(len(RemoveDuplicateDispatchedEventList))]\n",
    "    SortedDispatchedEventIdx = []\n",
    "    \n",
    "    for idx in range(len(RemoveDuplicateDispatchedEventList)):\n",
    "        smallest_idx = DispatchedEventRemainingIdx[0]\n",
    "        caseno,casesev,smallest_time,casetitle = RemoveDuplicateDispatchedEventList[smallest_idx].split('-~')\n",
    "        #print(\"Round {} Setting Smallest {}\".format(smallest_idx,casetime1))\n",
    "        for idx2,line2 in enumerate(RemoveDuplicateDispatchedEventList):\n",
    "            if idx2 in SortedDispatchedEventIdx:\n",
    "                continue\n",
    "            caseno2,casesev2,casetime2,casetitle2 = line2.split('-~')\n",
    "            if parser.parse(casetime2) < parser.parse(smallest_time):\n",
    "                #print(\"Found Smallest {} {}\".format(idx2,casetime2))\n",
    "                smallest_idx = idx2\n",
    "                smallest_time = casetime2 \n",
    "        #print(\"Round {} Smallext_idx {}\".format(idx,smallest_idx))\n",
    "        DispatchedEventRemainingIdx.remove(smallest_idx)\n",
    "        SortedDispatchedEventIdx.append(smallest_idx)\n",
    "    \n",
    "    SortedDispatchedEventList = []\n",
    "    for idx in SortedDispatchedEventIdx:\n",
    "        SortedDispatchedEventList.append(RemoveDuplicateDispatchedEventList[idx])\n",
    "        \n",
    "    return SortedDispatchedEventList\n",
    "\n",
    "RawDispatchedEventList = FindDispatchEvent(allevents,debug=True)\n",
    "RawDispatchedEventList[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689269541-~3-~2020-06-14 11:45:00-~01VN7W5,706 PROACTIVE CASE FOR ACI LEAF REBOOT (MEMORY LEAK CONTENTION)',\n",
       " '689251663-~4-~2020-06-14 12:45:00-~Wave 16 Migration Proactive Case',\n",
       " '689270154-~3-~2020-06-14 13:00:00-~ACI upgrade',\n",
       " '688771973-~2-~2020-06-14 14:00:00-~N9K-C93180YC-FX // Seeing some false in the ACI environment',\n",
       " '689232755-~3-~2020-06-14 14:00:00-~AMUNDI-Proactive SR for ACI-move of the legacy services into the ACI-June 14, 2020',\n",
       " '689279514-~3-~2020-06-14 14:00:00-~Preemptive case for ACI / NSX migration',\n",
       " '689280382-~3-~2020-06-15 11:45:00-~Proactive case: Migration of applications from old DC to new DC - ACI',\n",
       " '689225102-~3-~2020-06-17 13:00:00-~Connection from Palo Alto PA-3020 to Leaf Switch 9k not working for 1Gig Fiber SFP',\n",
       " '689277268-~3-~2020-06-20 14:00:00-~Preventive standby case for ACI MultiPod extension - Change# 8098051',\n",
       " '689222359-~3-~2020-06-21 10:00:00-~3.2(4e) || Santander Brazil| APIC FAULT F1527 high storage utilization',\n",
       " '689232755-~3-~2020-06-21 14:00:00-~AMUNDI-Proactive SR for ACI-move of the legacy services into the ACI-June 21, 2020']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RawDispatchedEventList[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Revming Dup Case - to be remoeved DUP FTS/UC\n",
      "689352135-~3-~WW-STORAGE-~2020-06-24 00:01:24\n",
      "689352135-~3-~WW-STORAGE-~2020-06-24 00:01:40\n",
      "689352150-~3-~WW-SV-~2020-06-24 00:02:17\n",
      "689352150-~3-~WW-SV-~2020-06-24 00:02:39\n",
      "689352110-~1-~UC-~2020-06-24 00:03:20\n",
      "689333106-~2-~FTS-~2020-06-24 00:03:32\n",
      "689352150-~3-~WW-SV-~2020-06-24 00:04:24\n",
      "689319966-~3-~UC-~2020-06-24 00:04:43\n",
      "689352135-~3-~WW-STORAGE-~2020-06-24 00:06:27\n",
      "689352159-~3-~WW-SV-~2020-06-24 00:06:31\n",
      "689352159-~3-~WW-SV-~2020-06-24 00:06:33\n",
      "689352159-~3-~WW-SV-~2020-06-24 00:06:43\n",
      "689352110-~1-~FTS-~2020-06-24 00:10:48\n",
      "689347849-~3-~WW-SV-~2020-06-24 00:11:20\n",
      "689347849-~3-~WW-SV-~2020-06-24 00:11:40\n",
      "689352202-~3-~WW-SV-~2020-06-24 00:22:28\n",
      "689352202-~3-~WW-SV-~2020-06-24 00:22:30\n",
      "689352202-~3-~WW-SV-~2020-06-24 00:22:41\n",
      "689352159-~3-~WW-SV-~2020-06-24 00:35:07\n",
      "689352159-~3-~WW-SV-~2020-06-24 00:35:12\n",
      "689347849-~3-~WW-SV-~2020-06-24 00:41:39\n",
      "689352202-~3-~WW-SV-~2020-06-24 00:52:41\n",
      "689352360-~3-~WW-STORAGE-~2020-06-24 01:09:28\n",
      "689352360-~3-~WW-STORAGE-~2020-06-24 01:09:36\n",
      "689352360-~3-~WW-STORAGE-~2020-06-24 01:09:51\n",
      "689352360-~3-~WW-STORAGE-~2020-06-24 01:09:57\n",
      "689352368-~3-~WW-STORAGE-~2020-06-24 01:16:35\n",
      "689352417-~3-~WW-SV-~2020-06-24 01:25:47\n",
      "689352417-~3-~WW-SV-~2020-06-24 01:25:48\n",
      "689352417-~3-~WW-SV-~2020-06-24 01:25:59\n",
      "689352368-~3-~WW-STORAGE-~2020-06-24 01:45:44\n",
      "689352637-~3-~WW-STORAGE-~2020-06-24 02:20:43\n",
      "689352637-~3-~WW-STORAGE-~2020-06-24 02:20:44\n",
      "689352639-~3-~WW-STORAGE-~2020-06-24 02:20:59\n",
      "689352639-~3-~WW-STORAGE-~2020-06-24 02:21:07\n",
      "689212357-~3-~WW-SV-~2020-06-24 02:30:17\n",
      "689212357-~3-~WW-SV-~2020-06-24 02:30:24\n",
      "689351184-~3-~WW-SV-~2020-06-24 03:00:16\n",
      "689352699-~3-~UC-~2020-06-24 03:38:36\n",
      "689352699-~3-~UC-~2020-06-24 03:41:35\n",
      "689272890-~3-~UC-~2020-06-24 03:43:07\n",
      "689264575-~3-~WW-STORAGE-~2020-06-24 03:56:29\n",
      "689264575-~2-~WW-STORAGE-~2020-06-24 03:56:49\n",
      "689353157-~3-~WW-SV-~2020-06-24 04:39:13\n",
      "689353157-~3-~WW-SV-~2020-06-24 04:39:15\n",
      "689353157-~3-~WW-SV-~2020-06-24 04:39:23\n",
      "689353213-~3-~WW-SV-~2020-06-24 04:53:24\n",
      "689353213-~3-~WW-SV-~2020-06-24 04:53:26\n",
      "689353213-~3-~WW-SV-~2020-06-24 04:53:35\n",
      "689133838-~1-~UC-~2020-06-24 04:55:02\n",
      "689331025-~3-~WW-SV-~2020-06-24 05:39:32\n",
      "689331025-~3-~WW-SV-~2020-06-24 05:39:39\n",
      "689353452-~4-~WW-SV-~2020-06-24 05:51:09\n",
      "689353452-~4-~WW-SV-~2020-06-24 05:51:11\n",
      "689353452-~4-~WW-SV-~2020-06-24 05:51:19\n",
      "689353487-~3-~WW-SV-~2020-06-24 05:58:42\n",
      "689353487-~3-~WW-SV-~2020-06-24 05:58:44\n",
      "689353487-~3-~WW-SV-~2020-06-24 05:58:53\n",
      "Found Dup Case 0 689352135 2020-06-24 00:01:24\n",
      "Found Dup Case 2 689352150 2020-06-24 00:02:17\n",
      "Found Dup Case 9 689352159 2020-06-24 00:06:31\n",
      "Found Dup Case 9 689352159 2020-06-24 00:06:31\n",
      "Found Dup Case 10 689352159 2020-06-24 00:06:33\n",
      "Found Dup Case 13 689347849 2020-06-24 00:11:20\n",
      "Found Dup Case 15 689352202 2020-06-24 00:22:28\n",
      "Found Dup Case 15 689352202 2020-06-24 00:22:28\n",
      "Found Dup Case 16 689352202 2020-06-24 00:22:30\n",
      "Found Dup Case 18 689352159 2020-06-24 00:35:07\n",
      "Found Dup Case 22 689352360 2020-06-24 01:09:28\n",
      "Found Dup Case 22 689352360 2020-06-24 01:09:28\n",
      "Found Dup Case 23 689352360 2020-06-24 01:09:36\n",
      "Found Dup Case 22 689352360 2020-06-24 01:09:28\n",
      "Found Dup Case 23 689352360 2020-06-24 01:09:36\n",
      "Found Dup Case 24 689352360 2020-06-24 01:09:51\n",
      "Found Dup Case 27 689352417 2020-06-24 01:25:47\n",
      "Found Dup Case 27 689352417 2020-06-24 01:25:47\n",
      "Found Dup Case 28 689352417 2020-06-24 01:25:48\n",
      "Found Dup Case 31 689352637 2020-06-24 02:20:43\n",
      "Found Dup Case 33 689352639 2020-06-24 02:20:59\n",
      "Found Dup Case 35 689212357 2020-06-24 02:30:17\n",
      "Found Dup Case 41 689264575 2020-06-24 03:56:29\n",
      "Found Dup Case 43 689353157 2020-06-24 04:39:13\n",
      "Found Dup Case 43 689353157 2020-06-24 04:39:13\n",
      "Found Dup Case 44 689353157 2020-06-24 04:39:15\n",
      "Found Dup Case 46 689353213 2020-06-24 04:53:24\n",
      "Found Dup Case 46 689353213 2020-06-24 04:53:24\n",
      "Found Dup Case 47 689353213 2020-06-24 04:53:26\n",
      "Found Dup Case 50 689331025 2020-06-24 05:39:32\n",
      "Found Dup Case 52 689353452 2020-06-24 05:51:09\n",
      "Found Dup Case 52 689353452 2020-06-24 05:51:09\n",
      "Found Dup Case 53 689353452 2020-06-24 05:51:11\n",
      "Found Dup Case 55 689353487 2020-06-24 05:58:42\n",
      "Found Dup Case 55 689353487 2020-06-24 05:58:42\n",
      "Found Dup Case 56 689353487 2020-06-24 05:58:44\n",
      "Dup UC index 38 with 39 and remove 38\n",
      "Dup Case List 0 2 9 10 13 15 16 18 22 23 24 27 28 31 33 35 41 43 44 46 47 50 52 53 55 56\n",
      "Dup FTS Case List \n",
      "Dup UC Case List 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['689352135-~3-~WW-STORAGE-~2020-06-24 00:01:40',\n",
       " '689352150-~3-~WW-SV-~2020-06-24 00:02:39',\n",
       " '689352110-~1-~UC-~2020-06-24 00:03:20',\n",
       " '689333106-~2-~FTS-~2020-06-24 00:03:32',\n",
       " '689352150-~3-~WW-SV-~2020-06-24 00:04:24',\n",
       " '689319966-~3-~UC-~2020-06-24 00:04:43',\n",
       " '689352135-~3-~WW-STORAGE-~2020-06-24 00:06:27',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:06:43',\n",
       " '689352110-~1-~FTS-~2020-06-24 00:10:48',\n",
       " '689347849-~3-~WW-SV-~2020-06-24 00:11:40',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:22:41',\n",
       " '689352159-~3-~WW-SV-~2020-06-24 00:35:12',\n",
       " '689347849-~3-~WW-SV-~2020-06-24 00:41:39',\n",
       " '689352202-~3-~WW-SV-~2020-06-24 00:52:41',\n",
       " '689352360-~3-~WW-STORAGE-~2020-06-24 01:09:57',\n",
       " '689352368-~3-~WW-STORAGE-~2020-06-24 01:16:35',\n",
       " '689352417-~3-~WW-SV-~2020-06-24 01:25:59',\n",
       " '689352368-~3-~WW-STORAGE-~2020-06-24 01:45:44',\n",
       " '689352637-~3-~WW-STORAGE-~2020-06-24 02:20:44',\n",
       " '689352639-~3-~WW-STORAGE-~2020-06-24 02:21:07',\n",
       " '689212357-~3-~WW-SV-~2020-06-24 02:30:24',\n",
       " '689351184-~3-~WW-SV-~2020-06-24 03:00:16',\n",
       " '689352699-~3-~UC-~2020-06-24 03:41:35',\n",
       " '689272890-~3-~UC-~2020-06-24 03:43:07',\n",
       " '689264575-~2-~WW-STORAGE-~2020-06-24 03:56:49',\n",
       " '689353157-~3-~WW-SV-~2020-06-24 04:39:23',\n",
       " '689353213-~3-~WW-SV-~2020-06-24 04:53:35',\n",
       " '689133838-~1-~UC-~2020-06-24 04:55:02',\n",
       " '689331025-~3-~WW-SV-~2020-06-24 05:39:39',\n",
       " '689353452-~4-~WW-SV-~2020-06-24 05:51:19',\n",
       " '689353487-~3-~WW-SV-~2020-06-24 05:58:53']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SortInQueueEventByTime(CaseInQueueList,date='2020-04-05',debug=True):\n",
    "    \n",
    "    CaseInQueueIndexSortByTime = []\n",
    "    CaseInQueueSortedAndRemoveList = []\n",
    "    CaseInQueueSortedRemaingList = [i for i in range(len(CaseInQueueList))]\n",
    "    CaseInQueueRemoveDupExtSortByTimeList = []\n",
    "    CaseInqueueRemoveDateSortByTimeList = []\n",
    "\n",
    "    shift_hour,gmt_hour = GetShiftHour(date)\n",
    "    \n",
    "    for index1, line1 in enumerate(CaseInQueueList):\n",
    "        \n",
    "        smallest_caseno,smallest_priority, smallest_queue,smallest_time = CaseInQueueList[CaseInQueueSortedRemaingList[0]].split(\"-~\")\n",
    "        smallest_datetime = dateutil.parser.parse(smallest_time)\n",
    "        CaseInQueueIndexSortByTime.append(CaseInQueueSortedRemaingList[0])\n",
    "        \n",
    "        for index2, line2 in enumerate(CaseInQueueList[:]):\n",
    "            \n",
    "            if index2 in CaseInQueueSortedAndRemoveList:\n",
    "                #if debug:\n",
    "                #    print(\"Skip {} {}\".format(index1,index2))\n",
    "                continue\n",
    "            caseno2, priority2, queue2, time2 = line2.split(\"-~\")\n",
    "            datetime2 = dateutil.parser.parse(time2)\n",
    "            \n",
    "            #if debug:\n",
    "                #print(\"Compare {} {} - {} {}\".format(CaseInQueueSortedRemaingList[0],smallest_datetime,index1+index2+1,datetime2))\n",
    "            \n",
    "            if datetime2 < smallest_datetime:\n",
    "                #if debug:\n",
    "                    #print(\"Found smaller index{}\".format(index2))\n",
    "                CaseInQueueIndexSortByTime[index1] = index2\n",
    "                smallest_datetime = datetime2\n",
    "                \n",
    "        #if debug:\n",
    "        #    print(\"Iteration {} pop {}\".format(index1,CaseInQueueIndexSortByTime[index1]))\n",
    "        CaseInQueueSortedAndRemoveList.append(CaseInQueueIndexSortByTime[index1])\n",
    "        CaseInQueueSortedRemaingList.remove(CaseInQueueIndexSortByTime[index1])\n",
    "        \n",
    "        #if debug:\n",
    "        #    print(CaseInQueueIndexSortByTime)\n",
    "        #    print(CaseInQueueSortedRemaingList)\n",
    "        #    print(\"Sorted Index from CaseInQueueList {}\".format(CaseInQueueIndexSortByTime))\n",
    "\n",
    "    for index in CaseInQueueIndexSortByTime:\n",
    "        CaseInQueueRemoveDupExtSortByTimeList.append(CaseInQueueList[index])\n",
    "    \n",
    "    if debug:\n",
    "        print(\"After Revming Dup Case - to be remoeved DUP FTS/UC\")\n",
    "        for caseline in CaseInQueueRemoveDupExtSortByTimeList:\n",
    "            print(caseline)\n",
    "    ###### Remove Dup FTS  List and only keep the last one ######\n",
    "    ###### Remove Dup UC  List and only keep the last one ######\n",
    "    ###### Remove Dup Case within 20 seconds and 2 event next to each other and only keep the last one ######\n",
    "    InQueueFTSList = [] #Index from CaseInQueueRemoveDupExtSortByTimeList #Case , #Timestamp\n",
    "    InQueueDupFTSIndexList = []\n",
    "    InQueueUCList = [] #Index from CaseInQueueRemoveDupExtSortByTimeList #Case , #Timestamp\n",
    "    InQueueDupUCIndexList = []\n",
    "\n",
    "    LastCaseList = [] #Index from CaseInQueueRemoveDupExtSortByTimeList #Case #Queue #Timestamp\n",
    "    InQueueDupCaseIndexList = []\n",
    "    \n",
    "    ######## Dup case condidition < 1 minutes\n",
    "    for index, caseline in enumerate(CaseInQueueRemoveDupExtSortByTimeList):\n",
    "        caseno, priority, queue, casetime = caseline.split(\"-~\")\n",
    "        if queue == 'FTS':\n",
    "            InQueueFTSList.append([index,caseno,casetime])\n",
    "        elif queue == 'UC':\n",
    "            InQueueUCList.append([index,caseno,casetime])\n",
    "        else:\n",
    "            for LastCase in LastCaseList:\n",
    "                if LastCase and LastCase[1] == caseno and LastCase[3] == queue:\n",
    "                    case_datetime = parser.parse(casetime)\n",
    "                    last_datetime = parser.parse(LastCase[4])\n",
    "                    ######## Dup case condition ######\n",
    "                    #1. same events come in < 60 seconds, 2 events in a row \n",
    "                    #2. priority are different , 2 events in a row\n",
    "                    if (case_datetime - last_datetime).seconds <= 60 or LastCase[2] != priority:\n",
    "                        if debug:\n",
    "                            print(\"Found Dup Case {} {} {}\".format(LastCase[0],caseno,LastCase[4]))\n",
    "                        InQueueDupCaseIndexList.append(LastCase[0])\n",
    "            LastCaseList.append([index,caseno,priority,queue,casetime])\n",
    "    InQueueDupCaseIndexList = set(InQueueDupCaseIndexList)\n",
    "    \n",
    "    ###### Get InQueueDupFTSIndexList in order ######\n",
    "    for index1, fts_case1 in enumerate(InQueueFTSList):\n",
    "        for index2, fts_case2 in enumerate(InQueueFTSList[index1+1:]):\n",
    "            if fts_case1[1] == fts_case2[1]:\n",
    "                if debug:\n",
    "                    print(\"Dup FTS index {} with {} and remove {}\".format(fts_case1[0],fts_case2[0],fts_case1[0]))\n",
    "                InQueueDupFTSIndexList.append(fts_case1[0])\n",
    "    ###### Get InQueueDupUCIndexList in order ######\n",
    "    for index1, uc_case1 in enumerate(InQueueUCList):\n",
    "        for index2, uc_case2 in enumerate(InQueueUCList[index1+1:]):\n",
    "            if uc_case1[1] == uc_case2[1]:\n",
    "                if debug:\n",
    "                    print(\"Dup UC index {} with {} and remove {}\".format(uc_case1[0],uc_case2[0],uc_case1[0]))\n",
    "                InQueueDupUCIndexList.append(uc_case1[0])\n",
    "    if debug:\n",
    "        print(\"Dup Case List {}\".format(\" \".join([str(index) for index in InQueueDupCaseIndexList])))\n",
    "        print(\"Dup FTS Case List {}\".format(\" \".join([str(index) for index in set(InQueueDupFTSIndexList)])))\n",
    "        print(\"Dup UC Case List {}\".format(\" \".join([str(index) for index in set(InQueueDupUCIndexList)])))\n",
    "        \n",
    "    InQueueDupIndexList = sorted([*InQueueDupCaseIndexList,*set(InQueueDupFTSIndexList),*set(InQueueDupUCIndexList)])\n",
    "    \n",
    "    for index in InQueueDupIndexList[::-1]:\n",
    "        CaseInQueueRemoveDupExtSortByTimeList.pop(index)\n",
    "        \n",
    "    ###### Remove Case which is not for that date ######\n",
    "    for caseline in CaseInQueueRemoveDupExtSortByTimeList:\n",
    "        caseno, priority, queue, time = caseline.split(\"-~\")\n",
    "        line_datetime = parser.parse(time)\n",
    "        if line_datetime.strftime(\"%Y-%m-%d\") == date:\n",
    "            CaseInqueueRemoveDateSortByTimeList.append(caseline)\n",
    "\n",
    "    return CaseInqueueRemoveDateSortByTimeList\n",
    "\n",
    "InQueueEventInOrderList = SortInQueueEventByTime(InQueueEventList,date=date,debug=True)\n",
    "InQueueEventInOrderList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SydQueueVol': 0,\n",
       " 'BGLQueueVol': 0,\n",
       " 'SydTakenVol': 0,\n",
       " 'BGLTakenVol': 0,\n",
       " 'FTSCaseVol': 9,\n",
       " 'UCCaseVol': 19,\n",
       " 'SydQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'BGLQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'SydTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'BGLTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'SydOnShiftEngr': 1,\n",
       " 'BGLOnShiftEngr': 1,\n",
       " 'SydOnShiftEngrTakenVol': 0,\n",
       " 'BGLOnShiftEngrTakenVol': 1,\n",
       " 'SYDHelper': 0,\n",
       " 'BGLHelper': 0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CaseStatsDic = {\"SydQueueVol\":0,\"BGLQueueVol\":0,\n",
    "            \"SydTakenVol\":0,\"BGLTakenVol\":0,\n",
    "            'FTSCaseVol':0,'UCCaseVol':0,\n",
    "            \"SydQueueVolByPri\":[0,0,0,0,0,0],\"BGLQueueVolByPri\":[0,0,0,0,0,0], #0 FTS #1,2,3,4 Priority #5 Urgent Collab\n",
    "            \"SydTakenVolByPri\":[0,0,0,0,0,0],\"BGLTakenVolByPri\":[0,0,0,0,0,0], #0 FTS #1,2,3,4 Priority #5 Urgent Collab\n",
    "            \"SydOnShiftEngr\":1,\"BGLOnShiftEngr\":1,\n",
    "            \"SydOnShiftEngrTakenVol\":0,\"BGLOnShiftEngrTakenVol\":1,\n",
    "            \"SYDHelper\":0,\"BGLHelper\":0,\n",
    "            }\n",
    "\n",
    "def GetStatsFromInQueueEventInOrderList(InQueueEventInOrderList,CaseStatsDic):\n",
    "    \n",
    "    ###### Getting partial CaseStatsDic Stats from the orderred List ######\n",
    "    for caseline in InQueueEventInOrderList:\n",
    "        caseno, priority, queue, time = caseline.split(\"-~\")\n",
    "        if 'SYD' in queue:\n",
    "            CaseStatsDic['SydQueueVol'] = CaseStatsDic['SydQueueVol'] + 1\n",
    "            CaseStatsDic['SydQueueVolByPri'][int(priority)] = CaseStatsDic['SydQueueVolByPri'][int(priority)]+1\n",
    "        elif 'BLR' in queue:\n",
    "            CaseStatsDic['BGLQueueVol'] = CaseStatsDic['BGLQueueVol'] + 1\n",
    "            CaseStatsDic['BGLQueueVolByPri'][int(priority)] = CaseStatsDic['BGLQueueVolByPri'][int(priority)]+1\n",
    "        elif 'FTS' in queue:\n",
    "            CaseStatsDic['FTSCaseVol'] = CaseStatsDic['FTSCaseVol'] + 1\n",
    "        elif 'UC' in queue:\n",
    "            CaseStatsDic['UCCaseVol'] = CaseStatsDic['UCCaseVol'] + 1\n",
    "    \n",
    "    return CaseStatsDic\n",
    "\n",
    "CaseStatsDic = GetStatsFromInQueueEventInOrderList(InQueueEventInOrderList,CaseStatsDic)\n",
    "CaseStatsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689352141-~3-~shajipas-~GCE-APAC-SV-~2020-06-24 00:05:10',\n",
       " '689346099-~3-~yudliu-~JAPAN-UCS-DL-~2020-06-24 00:04:06',\n",
       " '689326418-~3-~danyzhan-~UC_WORKGROUP-~2020-06-24 00:03:09',\n",
       " '689352110-~1-~kikirov-~SOF-SV-~2020-06-24 00:10:08',\n",
       " '689342595-~2-~gagambhi-~FTS_WORKGROUP-~2020-06-24 00:10:19',\n",
       " '689352168-~3-~aharalal-~GCE-APAC-SV-~2020-06-24 00:14:59',\n",
       " '689352150-~3-~gagambhi-~GCE-APAC-SV-~2020-06-24 00:17:09',\n",
       " '689342595-~2-~pvalecha-~GCE-APAC-SV-~2020-06-24 00:31:24',\n",
       " '689352135-~3-~donnylee-~APT-SV-~2020-06-24 00:31:23',\n",
       " '689352235-~3-~dinbai-~KR-SMARTNET-DL-~2020-06-24 00:34:00',\n",
       " '689352110-~1-~fbegumr-~GCE-APAC-SV-~2020-06-24 00:35:44',\n",
       " '689329060-~3-~icuyos-~APJ-SYD-SR-~2020-06-24 00:43:10',\n",
       " '689333106-~2-~sairusse-~APT-SV-~2020-06-24 00:46:22',\n",
       " '689347849-~3-~lyxiao-~APT-SV-~2020-06-24 00:56:33',\n",
       " '689352202-~3-~davdodd-~APT-SV-~2020-06-24 01:21:19',\n",
       " '689338055-~4-~prlalwan-~GCE-APAC-SV-~2020-06-24 01:22:56',\n",
       " '689325884-~4-~amangar-~GCE-APAC-SV-~2020-06-24 01:23:32',\n",
       " '689352433-~4-~sherholm-~Sherlock-~2020-06-24 01:30:34',\n",
       " '689327279-~4-~achikara-~GCE-APAC-SV-~2020-06-24 01:40:01',\n",
       " '689301841-~3-~rdevar-~GCE-APAC-SV-~2020-06-24 01:41:27',\n",
       " '689352417-~3-~rkumarya-~GCE-APAC-SV-~2020-06-24 01:43:49',\n",
       " '689352457-~3-~ananyraj-~GCE-APAC-SV-~2020-06-24 01:44:54',\n",
       " '689344575-~1-~anahar-~UC_WORKGROUP-~2020-06-24 01:46:56',\n",
       " '689352507-~3-~ranavada-~GCE-APAC-SV-~2020-06-24 01:53:48',\n",
       " '689352592-~4-~sherholm-~Sherlock-~2020-06-24 02:09:54',\n",
       " '689345038-~3-~anasthan-~CX-APAC-BLR-DCSoln-SSPT-~2020-06-24 02:16:25',\n",
       " '689352639-~3-~dachandr-~GCE-SV-~2020-06-24 02:42:29',\n",
       " '689352699-~3-~vnandan-~GCE-APAC-SV-~2020-06-24 02:45:33',\n",
       " '689323831-~2-~ngeraldl-~GCE-APAC-SV-~2020-06-24 03:05:21',\n",
       " '689351184-~3-~shajipas-~GCE-APAC-SV-~2020-06-24 03:06:20',\n",
       " '689212357-~3-~davdodd-~APT-SV-~2020-06-24 03:27:07',\n",
       " '689320020-~3-~fbegumr-~GCE-APAC-SV-~2020-06-24 03:32:12',\n",
       " '689343728-~3-~magaddam-~CX-APAC-BLR-DCSoln-SSPT-~2020-06-24 03:36:47',\n",
       " '689352721-~3-~taijjin-~JAPAN-UCS-DL-~2020-06-24 03:37:23',\n",
       " '689352892-~3-~sasingh5-~HTTS-INDIA-SV-~2020-06-24 03:52:28',\n",
       " '689352965-~3-~ricgupt4-~HTTS-INDIA-HARDWARE-~2020-06-24 03:55:09',\n",
       " '689344212-~3-~amangar-~GCE-APAC-SV-~2020-06-24 04:03:21',\n",
       " '689352981-~3-~gagambhi-~GCE-APAC-SV-~2020-06-24 04:03:37',\n",
       " '689264575-~2-~frjin-~APT-GC-UCS-~2020-06-24 04:04:26',\n",
       " '689352997-~3-~xuefejin-~JAPAN-UCS-DL-~2020-06-24 04:06:47',\n",
       " '689353056-~3-~prlalwan-~GCE-APAC-SV-~2020-06-24 04:16:26',\n",
       " '689353112-~4-~sherholm-~Sherlock-~2020-06-24 04:28:57',\n",
       " '689353146-~3-~mahks-~GCE-APAC-SV-~2020-06-24 04:37:41',\n",
       " '689353157-~3-~aharalal-~GCE-APAC-SV-~2020-06-24 04:43:54',\n",
       " '689353202-~3-~ckumarb-~GCE-APAC-SV-~2020-06-24 04:54:50',\n",
       " '689353213-~3-~rdevar-~GCE-APAC-SV-~2020-06-24 05:07:12',\n",
       " '689353319-~4-~sherholm-~Sherlock-~2020-06-24 05:17:56',\n",
       " '689353365-~3-~ranavada-~GCE-APAC-SV-~2020-06-24 05:32:56',\n",
       " '689353347-~3-~aharalal-~GCE-APAC-SV-~2020-06-24 05:33:10',\n",
       " '689024437-~3-~samuthia-~HTTS-INDIA-SV-~2020-06-24 05:36:20',\n",
       " '689353392-~3-~srmb-~GCE-APAC-SV-~2020-06-24 05:37:16',\n",
       " '689352699-~3-~anahar-~APT-SV-~2020-06-24 05:38:44',\n",
       " '689353413-~3-~aharalal-~GCE-APAC-SV-~2020-06-24 05:43:45',\n",
       " '689331025-~3-~nagordon-~APT-SV-~2020-06-24 05:58:12',\n",
       " '689353409-~3-~vischock-~GCE-APAC-SV-~2020-06-24 05:58:41',\n",
       " '689318518-~3-~afaizur-~HTTS-APAC-ENT1-~2020-06-24 05:59:22']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#/app/RabbitMQ_TAC_Event_Handler.py-2020-04-18 11:23:26,480-INFO-MQToRedis:688881426 3 Case_Accepted Chileaf402 -High SSD usage observed- Equipment Flash Warning taken by dashmari HTTS-EMEAR-DC-ACI at 2020-04-18 11:21:24\n",
    "\n",
    "def CaseAcceptInOrderByTime(AllEventsList,date='2020-02-27',debug=False):\n",
    "\n",
    "    shift_hour,gmt_hour = GetShiftHour(date)\n",
    "    \n",
    "    #1 Case No #2 Severity #3 CaseAccept Type Case|FTS|UC #4 ccoid #5 Workgroup #6 Time\n",
    "    Accept_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d)\\s(Case|FTS|UC)_Accepted.*\\sby\\s(\\w+)\\s(.*)\\s{0,1}at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    UC_Closed_Reg = re.compile(r'.*?MQToRedis:(\\d{9})\\s(\\d)\\sUC_Closed.*\\sby\\s(\\w+)\\s(.*)\\s{0,1}at\\s(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})')\n",
    "    \n",
    "    New_AllEventsList = []\n",
    "    for event in AllEventsList:\n",
    "        if 'Exception' not in event:\n",
    "            New_AllEventsList.append(event)\n",
    "            \n",
    "    CaseRawAcceptList = []\n",
    "    RawUCClosedList = []\n",
    "    \n",
    "    for line in AllEventsList:\n",
    "        if re.search(r'_Accepted',line):\n",
    "            result = re.search(Accept_Reg,line)\n",
    "            casetype = result.group(3).strip()\n",
    "            workgroup = result.group(5).strip()\n",
    "            if not workgroup:\n",
    "                workgroup = \"Unknown\"\n",
    "            if casetype == 'FTS':\n",
    "                workgroup = 'FTS_WORKGROUP'\n",
    "            elif casetype == 'UC':\n",
    "                workgroup = 'UC_WORKGROUP'\n",
    "            #print(\"Parsing Accept Case Result: {} {} {}\".format(line,casetype,workgroup))\n",
    "            CaseRawAcceptList.append(result.group(1)+\"-~\"+result.group(2)+\"-~\"+result.group(4)+\"-~\"+\n",
    "                                    workgroup+\"-~\"+result.group(6))\n",
    "        elif re.search(r'UC_Closed',line):\n",
    "            result = re.search(UC_Closed_Reg,line)\n",
    "            RawUCClosedList.append(result.group(1)+\"-~\"+result.group(2)+\"-~\"+result.group(3)+\"-~\"+\n",
    "                                    result.group(4)+\"-~\"+result.group(5))\n",
    "    \n",
    "    #CaseRawAcceptList = [re.search(Accept_Reg,line).group(1)+\"-~\"+\n",
    "    #                     re.search(Accept_Reg,line).group(2)+\"-~\"+\n",
    "    #                     re.search(Accept_Reg,line).group(4)+\"-~\"+\n",
    "    #                     re.search(Accept_Reg,line).group(5)+\"-~\"+\n",
    "    #                     re.search(Accept_Reg,line).group(6)\n",
    "    #                     for line in New_AllEventsList if re.search(r'_Accepted',line)]\n",
    "    \n",
    "    #print(\"CaseRawAcceptList {}\".format(CaseRawAcceptList))\n",
    "    #print(\"CasAcceptInOrderByTime:Raw Accept List Length {} UC_Closed_List {}\".format(len(CaseRawAcceptList),len(RawUCClosedList)))\n",
    "    \n",
    "    ###### Handling Accept Case ######\n",
    "    DuplicateAcceptIndexList = []\n",
    "    for index1, raw_case_line1 in enumerate(CaseRawAcceptList):\n",
    "        caseno1, severity1, queue1, workgroup, time1 = raw_case_line1.split(\"-~\")\n",
    "        for index2, raw_case_line2 in enumerate(CaseRawAcceptList[index1+1:]):\n",
    "            caseno2, severity2, queue2, workgroup, time2 = raw_case_line2.split(\"-~\")\n",
    "            if debug:\n",
    "                pass\n",
    "                #print(\"CasAcceptInOrderByTime:Comparing {} {} {} - {} {} {}\".format(caseno1,queue1,time1,caseno2,queue2,time2))\n",
    "            if caseno1 == caseno2 and time1 == time2:\n",
    "                if debug:\n",
    "                    print(\"Found dupliate {} {}\".format(index1,index1+index2+1))\n",
    "                DuplicateAcceptIndexList.append(index1+index2+1)\n",
    "    DuplicateAcceptIndexList = sorted(list(set(DuplicateAcceptIndexList)))\n",
    "    #print(\"CasAcceptInOrderByTime:Duplicate Case Index list {} {}\".format(len(DuplicateAcceptIndexList),DuplicateAcceptIndexList))\n",
    "    CaseAcceptRemoveDupExtList = [line for line in CaseRawAcceptList]\n",
    "    for index in DuplicateAcceptIndexList[::-1]:\n",
    "        #print(\"CasAcceptInOrderByTime:Pop duplicate {} from list\".format(index))\n",
    "        CaseAcceptRemoveDupExtList.pop(index)\n",
    "        #print(\"CasAcceptInOrderByTime:After removing DuplicateCase length {}\".format(len(CaseAcceptRemoveDupExtList)))\n",
    "        \n",
    "    #print(\"CaseAcceptRemoveDupExtList {}\".format(CaseAcceptRemoveDupExtList))\n",
    "    \n",
    "    ###### Remove the case Accept time out of the current date ######\n",
    "    CaseAcceptRemoveDupExtListWithDate = []\n",
    "    for caseline in CaseAcceptRemoveDupExtList:\n",
    "        #print(caseline)\n",
    "        caseno, severity, ccoid, workgroup, casetime = caseline.split(\"-~\")\n",
    "        line_datetime = parser.parse(casetime)\n",
    "        if line_datetime.strftime(\"%Y-%m-%d\") == date:\n",
    "            CaseAcceptRemoveDupExtListWithDate.append(caseline)\n",
    "    \n",
    "    #print(\"CaseAcceptRemoveDupExtListWithDate {}\".format(CaseAcceptRemoveDupExtListWithDate))\n",
    "    \n",
    "    UniqueAcceptEventInOrderList = []\n",
    "    for line in CaseAcceptRemoveDupExtListWithDate[::-1]:\n",
    "        caseno, severity, ccoid, workgroup, timestamp = line.split('-~')\n",
    "        isFoundDupCase = False\n",
    "        for uniline in UniqueAcceptEventInOrderList[::-1]:\n",
    "            unicaseno, severity, uniccoid, workgroup, unitimestamp = uniline.split('-~')\n",
    "            if (unicaseno == caseno) and (uniccoid == ccoid):\n",
    "                isFoundDupCase = True\n",
    "                break\n",
    "        if not isFoundDupCase:\n",
    "            UniqueAcceptEventInOrderList.append(line) \n",
    "    #print(\"UniqueAcceptEventInOrderList {}\".format(UniqueAcceptEventInOrderList))\n",
    "    \n",
    "    ##### Handling UC_Closed Case ######\n",
    "    DuplicateUCClosedIndexList = []\n",
    "    for index1, raw_case_line1 in enumerate(RawUCClosedList):\n",
    "        caseno1, severity1, ccoid1, workgroup1, time1 = raw_case_line1.split(\"-~\")\n",
    "        for index2, raw_case_line2 in enumerate(RawUCClosedList[index1+1:]):\n",
    "            caseno2, severity2, ccoid2, workgroup2, time2 = raw_case_line2.split(\"-~\")\n",
    "            #print(\"CasAcceptInOrderByTime:Comparing {} {} {} - {} {} {}\".format(caseno1,queue1,time1,caseno2,queue2,time2))\n",
    "            if caseno1 == caseno2 and time1 == time2:\n",
    "                #print(\"Found dupliate {} {}\".format(index1,index1+index2+1))\n",
    "                #DuplicateUCClosedIndexList.append(index1+index2+1)\n",
    "                DuplicateUCClosedIndexList.append(index1)\n",
    "    DuplicateUCClosedIndexList = sorted(list(set(DuplicateUCClosedIndexList)))\n",
    "    #print(\"CaseUC_Cosed:Duplicate Closed Index list {} {}\".format(len(DuplicateUCClosedIndexList),DuplicateUCClosedIndexList))\n",
    "    \n",
    "    CaseUCCLosedRemoveDupExtList = [line for line in RawUCClosedList]\n",
    "    for index in DuplicateUCClosedIndexList[::-1]:\n",
    "        #print(\"CasAcceptInOrderByTime:Pop duplicate {} from list\".format(index))\n",
    "        CaseUCCLosedRemoveDupExtList.pop(index)\n",
    "        #print(\"CasAcceptInOrderByTime:After removing DuplicateCase length {}\".format(len(CaseAcceptRemoveDupExtList)))\n",
    "    \n",
    "    ###### Remove the case UC_Closed time out of the current date ######\n",
    "    CaseUCClosedRemoveDupExtListWithDate = []\n",
    "    for caseline in CaseUCCLosedRemoveDupExtList:\n",
    "        caseno, severity, ccoid, workgroup, casetime = caseline.split(\"-~\")\n",
    "        line_datetime = parser.parse(casetime)\n",
    "        if line_datetime.strftime(\"%Y-%m-%d\") == date:\n",
    "            CaseUCClosedRemoveDupExtListWithDate.append(caseline)\n",
    "    \n",
    "    ###### From UniqueAcceptEventInOrderList remove UC_Closed by CaseUCClosedRemoveDupExtListWithDate ######\n",
    "    ###### 2020-06-15 UC_Closed shoud not affect Case_Accepted bug for cas689283906 ######\n",
    "    '''\n",
    "    Found UC_Closed 5 689283906-~3-~knagavol-~UC_WORKGROUP -~2020-06-14 10:35:50 -- Accept 16 689283906-~3-~knagavol-~GCE-ACI-Solutions-~2020-06-14 06:34:24\n",
    "    Found UC_Closed 2 689284486-~2-~prpratee-~UC_WORKGROUP -~2020-06-14 09:48:08 -- Accept 21 689284486-~2-~prpratee-~UC_WORKGROUP-~2020-06-14 06:05:16\n",
    "    '''\n",
    "    CaseAcceptRemoveUCClosedList = []\n",
    "    CaseAcceptRemoveUCClosedIndexList = []\n",
    "    for idx1,line1 in enumerate(UniqueAcceptEventInOrderList):\n",
    "        caseno1,casesev1,ccoid1,workgroup1,timestamp1 = line1.split(\"-~\")\n",
    "        for idx2,line2 in enumerate(CaseUCCLosedRemoveDupExtList):\n",
    "            caseno2,casesev2,ccoid2,workgroup2,timestamp2 = line2.split(\"-~\")\n",
    "            #if caseno1==caseno2 and ccoid1==ccoid2: #### adding workgroup comparasion\n",
    "            if caseno1==caseno2 and ccoid1==ccoid2 and workgroup1 == workgroup2:\n",
    "                print(\"Found UC_Closed {} {} -- Accept {} {}\".format(idx2,line2,idx1,line1))\n",
    "                CaseAcceptRemoveUCClosedIndexList.append(idx1)\n",
    "    CaseAcceptRemoveUCClosedList = [line for idx,line in enumerate(UniqueAcceptEventInOrderList) if idx not in CaseAcceptRemoveUCClosedIndexList]\n",
    "    #print(\"CaseAcceptRemoveUCClosedList {}\".format(CaseAcceptRemoveUCClosedList))\n",
    "    \n",
    "    return CaseAcceptRemoveUCClosedList[::-1]\n",
    "\n",
    "AcceptEventInOrderList = CaseAcceptInOrderByTime(allevents_in_date,date=date,debug=False)\n",
    "AcceptEventInOrderList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tonzeng',\n",
       "  'minkwong',\n",
       "  'siddhp',\n",
       "  'wilchong',\n",
       "  'debabbar',\n",
       "  'lindawa',\n",
       "  'junwa',\n",
       "  'annelso2',\n",
       "  'ikarvoun'],\n",
       " ['zdazhi', 'zmeng'],\n",
       " ['deepaky',\n",
       "  'knagavol',\n",
       "  'jawalia',\n",
       "  'prpratee',\n",
       "  'maveer',\n",
       "  'raghb',\n",
       "  'roagraw2',\n",
       "  'shparanj',\n",
       "  'vkalmath'],\n",
       " ['anirukas', 'reperuma', 'deepakba', 'bharatkc', 'kdoodi'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def UpdateEngrListFromAcceptEventInOrderList(AcceptEventInOrderList,EngrList,WKGroupList=['APT-ACI-SOLUTIONS','APT-ACI-SOLUTIONS2']):\n",
    "    \n",
    "    SYDEngrList = EngrList[0]\n",
    "    SYDOtherEngrList = EngrList[1]\n",
    "    BGLEngrList = EngrList[2]\n",
    "    BGLOtherEngrList = EngrList[3]\n",
    "    \n",
    "    Syd_group_Nname = WKGroupList[0]\n",
    "    BLR_group_name =WKGroupList[1]\n",
    "    \n",
    "    for caseline in AcceptEventInOrderList:\n",
    "        caseno, severity, ccoid, workgroup, time = caseline.split(\"-~\")\n",
    "        if workgroup == \"Unknown\":\n",
    "            continue\n",
    "        if workgroup == Syd_group_Nname:\n",
    "            if ccoid not in SYDEngrList:\n",
    "                SYDEngrList.append(ccoid)\n",
    "                print('Updating {} in SydEngrList'.format(ccoid))\n",
    "        elif workgroup == BLR_group_name:\n",
    "            if ccoid not in BGLEngrList:\n",
    "                print('Updating {} in BGLEngrList'.format(ccoid))\n",
    "                BGLEngrList.append(ccoid)\n",
    "                if ccoid in BGLOtherEngrList:\n",
    "                    print('Removing {} from BGLOtherEngrList'.format(ccoid))\n",
    "                    BGLOtherEngrList.remove(ccoid)\n",
    "            elif ccoid in BGLOtherEngrList:\n",
    "                print('Updating {} in BGLOtherEngrList'.format(ccoid))\n",
    "                if ccoid in BGLEngrList:\n",
    "                    print('Removing {} from BGLEngrList'.format(ccoid))\n",
    "                    BGLEngrList.remove(ccoid)\n",
    "                    \n",
    "    return [SYDEngrList,SYDOtherEngrList,BGLEngrList,BGLOtherEngrList]\n",
    "                    \n",
    "SYDEngrList,SYDOtherEngrList,BGLEngrList,BGLOtherEngrList = UpdateEngrListFromAcceptEventInOrderList(AcceptEventInOrderList,[SYDEngrList,SYDOtherEngrList,BGLEngrList,BGLOtherEngrList])\n",
    "\n",
    "SYDEngrList,SYDOtherEngrList,BGLEngrList, BGLOtherEngrList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SydQueueVol': 0,\n",
       " 'BGLQueueVol': 0,\n",
       " 'SydTakenVol': 0,\n",
       " 'BGLTakenVol': 0,\n",
       " 'FTSCaseVol': 0,\n",
       " 'UCCaseVol': 0,\n",
       " 'SydQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'BGLQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'SydTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'BGLTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       " 'SydOnShiftEngr': [],\n",
       " 'BGLOnShiftEngr': [],\n",
       " 'SydOnShiftEngrTakenVol': 0,\n",
       " 'BGLOnShiftEngrTakenVol': 1,\n",
       " 'SYDHelper': [],\n",
       " 'BGLHelper': []}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Case Accept Stats ######\n",
    "def GetStatsFromCaseAcceptInOrderByTime(AcceptEventInOrderList,CaseStatsDic,EngrList):\n",
    "    \n",
    "    SYDEngrList = EngrList[0]\n",
    "    SYDOtherEngrList = EngrList[1]\n",
    "    BGLEngrList = EngrList[2]\n",
    "    BGLOtherEngrList = EngrList[3]\n",
    "        \n",
    "    SydOnShiftEngrList = []\n",
    "    SydOtherOnshiftEngrList = []\n",
    "\n",
    "    BGLOnShiftEngrList = []\n",
    "    BGLOtherOnshiftEngrList = []\n",
    "    \n",
    "    ###### Getting partial CaseStatsDic Stats from the orderred List ######\n",
    "    for caseline in AcceptEventInOrderList:\n",
    "        caseno, severity, ccoid, workgroup, time = caseline.split(\"-~\")\n",
    "        if ccoid in SYDEngrList:\n",
    "            if ccoid not in SydOnShiftEngrList:\n",
    "                SydOnShiftEngrList.append(ccoid)\n",
    "        elif ccoid in SYDOtherEngrList:\n",
    "            if ccoid not in SydOtherOnshiftEngrList:\n",
    "                SydOtherOnshiftEngrList.append(ccoid)\n",
    "        elif ccoid in BGLEngrList:\n",
    "            if ccoid not in BGLOnShiftEngrList:\n",
    "                BGLOnShiftEngrList.append(ccoid)\n",
    "        elif ccoid in BGLOtherEngrList:\n",
    "            if ccoid not in BGLOtherOnshiftEngrList:\n",
    "                BGLOtherOnshiftEngrList.append(ccoid)\n",
    "                \n",
    "    CaseStatsDic['SydOnShiftEngr'] = SydOnShiftEngrList\n",
    "    CaseStatsDic['BGLOnShiftEngr'] = BGLOnShiftEngrList\n",
    "    CaseStatsDic['SYDHelper'] = SydOtherOnshiftEngrList\n",
    "    CaseStatsDic['BGLHelper'] = BGLOtherOnshiftEngrList\n",
    "    \n",
    "    return CaseStatsDic\n",
    "\n",
    "CaseStatsDic = GetStatsFromCaseAcceptInOrderByTime(AcceptEventInOrderList,CaseStatsDic,[SYDEngrList,SYDOtherEngrList,BGLEngrList,BGLOtherEngrList])\n",
    "CaseStatsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'689352141': ['shajipas(Unknown)'],\n",
       "  '689346099': ['yudliu(Unknown)'],\n",
       "  '689326418': ['danyzhan(Unknown)'],\n",
       "  '689352110': ['kikirov(Unknown)', 'fbegumr(Unknown)'],\n",
       "  '689342595': ['gagambhi(Unknown)', 'pvalecha(Unknown)'],\n",
       "  '689352168': ['aharalal(Unknown)'],\n",
       "  '689352150': ['gagambhi(Unknown)'],\n",
       "  '689352135': ['donnylee(Unknown)'],\n",
       "  '689352235': ['dinbai(Unknown)'],\n",
       "  '689329060': ['icuyos(Unknown)'],\n",
       "  '689333106': ['sairusse(Unknown)'],\n",
       "  '689347849': ['lyxiao(Unknown)'],\n",
       "  '689352202': ['davdodd(Unknown)'],\n",
       "  '689338055': ['prlalwan(Unknown)'],\n",
       "  '689325884': ['amangar(Unknown)'],\n",
       "  '689352433': ['sherholm(Unknown)'],\n",
       "  '689327279': ['achikara(Unknown)'],\n",
       "  '689301841': ['rdevar(Unknown)'],\n",
       "  '689352417': ['rkumarya(Unknown)'],\n",
       "  '689352457': ['ananyraj(Unknown)'],\n",
       "  '689344575': ['anahar(Unknown)'],\n",
       "  '689352507': ['ranavada(Unknown)'],\n",
       "  '689352592': ['sherholm(Unknown)'],\n",
       "  '689345038': ['anasthan(Unknown)'],\n",
       "  '689352639': ['dachandr(Unknown)'],\n",
       "  '689352699': ['vnandan(Unknown)', 'anahar(Unknown)'],\n",
       "  '689323831': ['ngeraldl(Unknown)'],\n",
       "  '689351184': ['shajipas(Unknown)'],\n",
       "  '689212357': ['davdodd(Unknown)'],\n",
       "  '689320020': ['fbegumr(Unknown)'],\n",
       "  '689343728': ['magaddam(Unknown)'],\n",
       "  '689352721': ['taijjin(Unknown)'],\n",
       "  '689352892': ['sasingh5(Unknown)'],\n",
       "  '689352965': ['ricgupt4(Unknown)'],\n",
       "  '689344212': ['amangar(Unknown)'],\n",
       "  '689352981': ['gagambhi(Unknown)'],\n",
       "  '689264575': ['frjin(Unknown)'],\n",
       "  '689352997': ['xuefejin(Unknown)'],\n",
       "  '689353056': ['prlalwan(Unknown)'],\n",
       "  '689353112': ['sherholm(Unknown)'],\n",
       "  '689353146': ['mahks(Unknown)'],\n",
       "  '689353157': ['aharalal(Unknown)'],\n",
       "  '689353202': ['ckumarb(Unknown)'],\n",
       "  '689353213': ['rdevar(Unknown)'],\n",
       "  '689353319': ['sherholm(Unknown)'],\n",
       "  '689353365': ['ranavada(Unknown)'],\n",
       "  '689353347': ['aharalal(Unknown)'],\n",
       "  '689024437': ['samuthia(Unknown)'],\n",
       "  '689353392': ['srmb(Unknown)'],\n",
       "  '689353413': ['aharalal(Unknown)'],\n",
       "  '689331025': ['nagordon(Unknown)'],\n",
       "  '689353409': ['vischock(Unknown)'],\n",
       "  '689318518': ['afaizur(Unknown)']},\n",
       " {'SydQueueVol': 0,\n",
       "  'BGLQueueVol': 0,\n",
       "  'SydTakenVol': 0,\n",
       "  'BGLTakenVol': 0,\n",
       "  'FTSCaseVol': 0,\n",
       "  'UCCaseVol': 0,\n",
       "  'SydQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       "  'BGLQueueVolByPri': [0, 0, 0, 0, 0, 0],\n",
       "  'SydTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       "  'BGLTakenVolByPri': [0, 0, 0, 0, 0, 0],\n",
       "  'SydOnShiftEngr': [],\n",
       "  'BGLOnShiftEngr': [],\n",
       "  'SydOnShiftEngrTakenVol': 0,\n",
       "  'BGLOnShiftEngrTakenVol': 1,\n",
       "  'SYDHelper': [],\n",
       "  'BGLHelper': []})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CaseTakenByEngrDic = {}\n",
    "\n",
    "for case in AcceptEventInOrderList:\n",
    "    \n",
    "    caseno,severity,ccoid,workgroup,time = case.split(\"-~\")\n",
    "    if ccoid not in CaseTakenDic.keys():\n",
    "        CaseTakenDic[ccoid] = []\n",
    "    if caseno not in CaseTakenDic[ccoid]:\n",
    "        CaseTakenDic[ccoid].append(caseno)\n",
    "    if ccoid not in OnShiftEngrList and (ccoid in SYDEngrList or ccoid in BGLEngrList \n",
    "                                         or ccoid in BGLOtherEngrList or ccoid in SYDOtherEngrList):\n",
    "        OnShiftEngrList.append(ccoid)\n",
    "    if caseno not in CaseTakenByEngrDic.keys():\n",
    "        CaseTakenByEngrDic[caseno] = []\n",
    "        \n",
    "    if ccoid in SYDEngrList or ccoid in SYDOtherEngrList:\n",
    "        CaseStatsDic['SydTakenVolByPri'][int(severity)] = CaseStatsDic['SydTakenVolByPri'][int(severity)] + 1\n",
    "        CaseTakenByEngrDic[caseno].append(ccoid+\"(SYD)\")\n",
    "    elif ccoid in BGLEngrList or ccoid in BGLOtherEngrList:\n",
    "        CaseStatsDic['BGLTakenVolByPri'][int(severity)] = CaseStatsDic['BGLTakenVolByPri'][int(severity)] + 1\n",
    "        CaseTakenByEngrDic[caseno].append(ccoid+\"(BLR)\")\n",
    "    elif ccoid == 'lowtouch':\n",
    "        CaseTakenByEngrDic[caseno].append(ccoid+\"(HW)\")\n",
    "    else:\n",
    "        CaseTakenByEngrDic[caseno].append(ccoid+\"(Unknown)\")\n",
    "        \n",
    "CaseTakenByEngrDic,CaseStatsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SYD': {}, 'SYD_Other': {}, 'BGL': {}, 'BGL_Other': {}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ccoid, caselist in CaseTakenDic.items():\n",
    "    if ccoid in SYDEngrList:\n",
    "        CaseTakenDicInclNo['SYD'][ccoid] = list([len(caselist),*caselist])\n",
    "    elif ccoid in SYDOtherEngrList:\n",
    "        CaseTakenDicInclNo['SYD_Other'][ccoid] = list([len(caselist),*caselist])\n",
    "    elif ccoid in BGLEngrList:\n",
    "        CaseTakenDicInclNo['BGL'][ccoid] = list([len(caselist),*caselist])\n",
    "    elif ccoid in BGLOtherEngrList:\n",
    "        CaseTakenDicInclNo['BGL_Other'][ccoid] = list([len(caselist),*caselist])\n",
    "CaseTakenDicInclNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-17\n",
      "[0, 6]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['689304293-~1-~FTS-~2020-06-17 10:01:32-~siddhp(SYD)-~minkwong(SYD)',\n",
       " '689302095-~3-~FTS-~2020-06-17 10:03:24-~deepaky(BLR)',\n",
       " '689299756-~2-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 10:07:04-~siddhp(SYD)',\n",
       " '689292729-~1-~FTS-~2020-06-17 10:24:03-~hethakur(Unknown)',\n",
       " '689302558-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 10:37:18']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_hour,gmt_hour = ACILib.GetShiftHour(date)\n",
    "print(date)\n",
    "print(shift_hour)\n",
    "print(gmt_hour)\n",
    "\n",
    "InQueueEventInOrderListWithEngr = []\n",
    "for caseline in InQueueEventInOrderList:\n",
    "    caseno,priority,queue,timestamp = caseline.split(\"-~\")\n",
    "    ###### CaseStatsDic FTS Stats ######\n",
    "    if queue == 'FTS':\n",
    "        for ccoid,caselist in CaseTakenDic.items():\n",
    "            if caseno in caselist:\n",
    "                if ccoid in SYDEngrList or ccoid in SYDOtherEngrList:\n",
    "                    CaseStatsDic['SydTakenVolByPri'][0] = CaseStatsDic['SydTakenVolByPri'][0] + 1\n",
    "                    #CaseStatsDic['SydTakenVol'] = CaseStatsDic['SydTakenVol'] + 1\n",
    "                elif ccoid in BGLEngrList or ccoid in BGLOtherEngrList:\n",
    "                    CaseStatsDic['BGLTakenVolByPri'][0] = CaseStatsDic['BGLTakenVolByPri'][0] + 1\n",
    "                    #CaseStatsDic['BGLTakenVol'] = CaseStatsDic['BGLTakenVol'] + 1\n",
    "    \n",
    "    ###### CaseStatsDic UC Stats ######\n",
    "    elif queue == 'UC':\n",
    "        for ccoid,caselist in CaseTakenDic.items():\n",
    "            if caseno in caselist:\n",
    "                if ccoid in SYDEngrList or ccoid in SYDOtherEngrList:\n",
    "                    CaseStatsDic['SydTakenVolByPri'][5] = CaseStatsDic['SydTakenVolByPri'][5] + 1\n",
    "                    #CaseStatsDic['SydTakenVol'] = CaseStatsDic['SydTakenVol'] + 1\n",
    "                elif ccoid in BGLEngrList or ccoid in BGLOtherEngrList:\n",
    "                    CaseStatsDic['BGLTakenVolByPri'][5] = CaseStatsDic['BGLTakenVolByPri'][5] + 1   \n",
    "                    #CaseStatsDic['BGLTakenVol'] = CaseStatsDic['BGLTakenVol'] + 1\n",
    "    \n",
    "    if caseno in CaseTakenByEngrDic.keys():\n",
    "        InQueueEventInOrderListWithEngr.append(caseno+'-~'+priority+\"-~\"+queue+'-~'+\n",
    "                                               (parser.parse(timestamp)+datetime.timedelta(hours=(gmt_hour+shift_hour[0]))).strftime(\"%Y-%m-%d %H:%M:%S\")+\n",
    "                                               '-~'+\"-~\".join(CaseTakenByEngrDic[caseno]))\n",
    "    else:\n",
    "        InQueueEventInOrderListWithEngr.append(caseno+'-~'+priority+\"-~\"+queue+'-~'+\n",
    "                                               (parser.parse(timestamp)+datetime.timedelta(hours=(gmt_hour+shift_hour[0]))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                                               )\n",
    "InQueueEventInOrderListWithEngr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read JSON file /home/jovyan/HTTSDashboard/logs/TAC/APJC/ACI/events/2020_InQueueEvent.json\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-0f43fa119886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mInQueueEvents_by_year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mInQueueEvents_by_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindInQueueEventsFromEventFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueuefilelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mInQueueEvents_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2020\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-0f43fa119886>\u001b[0m in \u001b[0;36mFindInQueueEventsFromEventFile\u001b[0;34m(inqueuefilelist)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minqueuefile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minqueuefilelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read JSON file {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueuefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mReadInQueueEvents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueuefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReadInQueueEvents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#with open(inqueuefile,'r') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json,glob\n",
    "###### InQueue file parsing Read the current Parsing file 2020_InQueue.txt ######\n",
    "jupyter_container_path = '/home/jovyan'\n",
    "flask_container_path = ''\n",
    "current_container_path = jupyter_container_path\n",
    "inqueuefilenames = current_container_path + '/HTTSDashboard/logs/ACI/events/*_InQueueEvent.txt'\n",
    "inqueuefilenames = current_container_path + '/HTTSDashboard/logs/TAC/APJC/ACI/events/*_InQueueEvent.json'\n",
    "inqueuefilelist = glob.glob(inqueuefilenames)\n",
    "\n",
    "def FindInQueueEventsFromEventFile(inqueuefilelist):\n",
    "\n",
    "    if len(inqueuefilelist) == 0:\n",
    "        return\n",
    "    InQueueEvents_by_year = {}\n",
    "    \n",
    "    for inqueuefile in inqueuefilelist:\n",
    "        print(\"Read JSON file {}\".format(inqueuefile))\n",
    "        ReadInQueueEvents = json.loads(inqueuefile)\n",
    "        print(ReadInQueueEvents)\n",
    "        #with open(inqueuefile,'r') as f:\n",
    "            #ReadInQueueEvents = f.readlines()\n",
    "        #f.close()\n",
    "        #ReadInQueueEvents = [event.strip() for event in ReadInQueueEvents if event.strip()]\n",
    "        #for event in ReadInQueueEvents:\n",
    "            #caseno, casesev, queue , timestamp = event.split(\"-~\")\n",
    "            #caseyear = parser.parse(timestamp).year\n",
    "            #if caseyear not in InQueueEvents_by_year.keys():\n",
    "                #InQueueEvents_by_year[caseyear] = []\n",
    "            #InQueueEvents_by_year[caseyear].append(event)\n",
    "        InQueueEvents_by_year = InQueueEvents_by_year + ReadInQueueEvents\n",
    "        \n",
    "    return InQueueEvents_by_year\n",
    "\n",
    "InQueueEvents_by_year = FindInQueueEventsFromEventFile(inqueuefilelist)\n",
    "InQueueEvents_by_year[2020][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove event 2141 689302558-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 00:37:18\n",
      "Remove event 2140 689292729-~1-~FTS-~2020-06-17 00:24:03\n",
      "Remove event 2139 689299756-~2-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 00:07:04\n",
      "Remove event 2138 689302095-~3-~FTS-~2020-06-17 00:03:24\n",
      "Remove event 2137 689304293-~1-~FTS-~2020-06-17 00:01:32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['689228533-~2-~UC-~2020-06-16 01:48:25',\n",
       " '689295023-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 01:55:09',\n",
       " '689057549-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:00:09',\n",
       " '689295420-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:37:06',\n",
       " '689295339-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:46:05',\n",
       " '689283509-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 04:05:59',\n",
       " '689295568-~3-~WW-Rakuten-ACI-~2020-06-16 04:15:30',\n",
       " '689288521-~1-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 04:44:45',\n",
       " '689295702-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-16 04:48:26',\n",
       " '689295926-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 05:41:43']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######Function to remove a speicifc date inqueue events ######\n",
    "def RemoveInQueueEventByDateFromFile(date,InQueueEvents):\n",
    "    #print(date)\n",
    "    if not InQueueEvents:\n",
    "        return {}\n",
    "    RemovedDateInQueueEvents = copy.deepcopy(InQueueEvents)\n",
    "    #print(InQueueEvents[2020][-10:])\n",
    "    for year,events in InQueueEvents.items():\n",
    "        for index,event in enumerate(InQueueEvents[year][::-1]):\n",
    "            caseno,severity,queue,casetime = event.split('-~')\n",
    "            if parser.parse(casetime).strftime(\"%Y-%m-%d\") == date:\n",
    "                print(\"Remove event {} {}\".format(len(InQueueEvents[year])-index-1,event))\n",
    "                RemovedDateInQueueEvents[year].pop(len(InQueueEvents[year])-index-1)\n",
    "            if parser.parse(casetime) < parser.parse(date):\n",
    "                break\n",
    "    return RemovedDateInQueueEvents\n",
    "\n",
    "date = (datetime.datetime.today() - datetime.timedelta(days=0)).strftime(\"%Y-%m-%d\")\n",
    "RemovedInQueueEvents = RemoveInQueueEventByDateFromFile(date,InQueueEvents_by_year)\n",
    "RemovedInQueueEvents[2020][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689286693-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-15 05:21:09',\n",
       " '688883579-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-15 05:39:35',\n",
       " '689228533-~2-~UC-~2020-06-15 05:40:58',\n",
       " '688883579-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-15 05:41:14',\n",
       " '689286431-~2-~FTS-~2020-06-16 00:00:13',\n",
       " '689287181-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 00:00:19',\n",
       " '689294350-~2-~FTS-~2020-06-16 00:01:22',\n",
       " '689275926-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 00:50:00',\n",
       " '689294826-~2-~CX-APJC-SYD-ACI-SSPT-~2020-06-16 00:54:06',\n",
       " '689294864-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-16 01:04:44',\n",
       " '689228533-~2-~UC-~2020-06-16 01:48:25',\n",
       " '689295023-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 01:55:09',\n",
       " '689057549-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:00:09',\n",
       " '689295420-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:37:06',\n",
       " '689295339-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 03:46:05',\n",
       " '689283509-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 04:05:59',\n",
       " '689295568-~3-~WW-Rakuten-ACI-~2020-06-16 04:15:30',\n",
       " '689288521-~1-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 04:44:45',\n",
       " '689295702-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-16 04:48:26',\n",
       " '689304293-~1-~FTS-~2020-06-17 00:01:32',\n",
       " '689302095-~3-~FTS-~2020-06-17 00:03:24',\n",
       " '689299756-~2-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 00:07:04',\n",
       " '689292729-~1-~FTS-~2020-06-17 00:24:03',\n",
       " '689302558-~3-~CX-APJC-SYD-ACI-SSPT-~2020-06-17 00:37:18',\n",
       " '689295926-~3-~CX-APJC-BLR-ACI-SSPT-~2020-06-16 05:41:43']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AddEventList = InQueueEventInOrderList\n",
    "\n",
    "######Function to add a speicifc date inqueue inorder events ######\n",
    "def AddInQueueEventByDateFromFile(date,AddList,InQueueEvents):\n",
    "    if not InQueueEvents:\n",
    "        InQueueEvents = {}\n",
    "    if parser.parse(date).year not in InQueueEvents.keys():\n",
    "        InQueueEvents[parser.parse(date).year] = []\n",
    "    ######Need to deep copy the list ######\n",
    "    AddedDateInQueueEvents = copy.deepcopy(InQueueEvents)\n",
    "    insert_index = len(InQueueEvents)\n",
    "    for year, events in InQueueEvents.items():\n",
    "        for index,event in enumerate(InQueueEvents[year][::-1]):\n",
    "            caseno,severity,queue,casetime = event.split('-~')\n",
    "            if parser.parse(casetime).date() > parser.parse(date).date():\n",
    "                insert_index = index\n",
    "                break\n",
    "        insert_idex = len(AddedDateInQueueEvents[year])-insert_index\n",
    "        for event in AddList[::]:\n",
    "            AddedDateInQueueEvents[year].insert(len(AddedDateInQueueEvents[year])-insert_index,event)\n",
    "    return AddedDateInQueueEvents\n",
    "\n",
    "date = (datetime.datetime.today() - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "AddedDateInQueueEvents = AddInQueueEventByDateFromFile(date,AddEventList,RemovedInQueueEvents)\n",
    "AddedDateInQueueEvents[2020][-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/HTTSDashboard/logs/TAC/EMEA/ACI/events/2020_AcceptEvent.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['689297447-~3-~bharatkc-~GCE-ACI-Solutions-~2020-06-16 10:18:03',\n",
       " '689297636-~3-~hazyouse-~EMEAR-ORCH-ACI-~2020-06-16 10:36:29',\n",
       " '689297541-~3-~anirukas-~GCE-ACI-Solutions-~2020-06-16 10:11:37',\n",
       " '689297941-~3-~apubillo-~EMEAR-ORCH-ACI-~2020-06-16 11:10:46',\n",
       " '689297867-~3-~dgomezbe-~EMEAR-ORCH-ACI-~2020-06-16 11:11:32',\n",
       " '689223969-~3-~ansaldar-~US-ACI-SOL-EAST-~2020-06-16 11:14:45',\n",
       " '689298167-~3-~vlvenkat-~GCE-ACI-Solutions-~2020-06-16 11:49:40',\n",
       " '689297885-~3-~visgupt2-~GCE-ACI-Solutions-~2020-06-16 11:49:55',\n",
       " '689298148-~3-~pcozende-~EMEAR-ORCH-ACI-~2020-06-16 11:52:13',\n",
       " '689258814-~4-~amatahen-~EMEAR-ORCH-ACI-~2020-06-16 11:52:46']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "###### Accept file parsing Read the current Parsing file 2020_InQueue.txt ######\n",
    "jupyter_container_path = '/home/jovyan'\n",
    "flask_container_path = ''\n",
    "current_container_path = jupyter_container_path\n",
    "eventfilenames = current_container_path + '/HTTSDashboard/logs/ACI/events/*_AcceptEvent.txt'\n",
    "eventfilenames = current_container_path + '/HTTSDashboard/logs/TAC/EMEA/ACI/events/*_AcceptEvent.txt'\n",
    "acceptfilelist = glob.glob(eventfilenames)\n",
    "\n",
    "def FindAcceptEventsFromEventFile(acceptfilelist):\n",
    "    if len(acceptfilelist) == 0:\n",
    "        return\n",
    "    AcceptEvents_by_year = {}\n",
    "    ###### Accept file parsing Read the current Parsing file 2020_InQueue.txt ######\n",
    "    for acceptfile in acceptfilelist:\n",
    "        print(acceptfile)\n",
    "        with open(acceptfile,'r') as f:\n",
    "            ReadAcceptEvents = f.readlines()\n",
    "        f.close()\n",
    "        ReadAcceptEvents = [event.strip() for event in ReadAcceptEvents if event.strip()]\n",
    "        for event in ReadAcceptEvents:\n",
    "            caseno, casesev, ccoid,workgroup,timestamp = event.split(\"-~\")\n",
    "            caseyear = parser.parse(timestamp).year\n",
    "            if caseyear not in AcceptEvents_by_year.keys():\n",
    "                AcceptEvents_by_year[caseyear] = []\n",
    "            AcceptEvents_by_year[caseyear].append(event)\n",
    "    return AcceptEvents_by_year\n",
    "    \n",
    "AcceptEvents_by_year = FindAcceptEventsFromEventFile(acceptfilelist)\n",
    "AcceptEvents_by_year[2020][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689243117-~3-~amatahen-~EMEAR-ORCH-ACI-~2020-06-15 08:08:42',\n",
       " '689166638-~3-~deepakba-~UC_WORKGROUP-~2020-06-15 08:09:52',\n",
       " '689287483-~3-~hazyouse-~EMEAR-ORCH-ACI-~2020-06-15 08:13:47',\n",
       " '689096740-~3-~deepakba-~UC_WORKGROUP-~2020-06-15 08:13:53',\n",
       " '689057549-~3-~deepakba-~UC_WORKGROUP-~2020-06-15 08:17:37',\n",
       " '689287668-~3-~deseth2-~GCE-ACI-Solutions-~2020-06-15 08:22:05',\n",
       " '688891171-~3-~deepakba-~UC_WORKGROUP-~2020-06-15 08:32:23',\n",
       " '689287737-~3-~ralhalab-~AMM-ACI-~2020-06-15 08:32:08',\n",
       " '689287679-~3-~mapedro-~EMEAR-ORCH-ACI-~2020-06-15 08:45:45',\n",
       " '689287922-~3-~lowtouch-~VIRTUAL-~2020-06-15 08:52:34',\n",
       " '689287944-~2-~mapedro-~EMEAR-ORCH-ACI-~2020-06-15 08:59:53',\n",
       " '689284852-~3-~knagavol-~GCE-ACI-Solutions-~2020-06-15 09:03:51',\n",
       " '689287895-~3-~pcozende-~EMEAR-ORCH-ACI-~2020-06-15 09:11:06',\n",
       " '689286199-~3-~birai-~GCE-ACI-Solutions-~2020-06-15 09:12:44',\n",
       " '689287922-~3-~rbushnaq-~AMM-ACI-~2020-06-15 09:27:44',\n",
       " '689058098-~3-~anirukas-~GCE-ACI-Solutions-~2020-06-15 09:27:46',\n",
       " '689287943-~3-~halhadda-~AMM-ACI-~2020-06-15 09:36:09',\n",
       " '689287969-~3-~dgomezbe-~EMEAR-ORCH-ACI-~2020-06-15 09:36:47',\n",
       " '689288363-~3-~lowtouch-~VIRTUAL-~2020-06-15 09:56:17',\n",
       " '689288388-~3-~amponnus-~CA-MANAGER-~2020-06-15 10:02:19',\n",
       " '689285538-~3-~apubillo-~EMEAR-ORCH-ACI-~2020-06-15 10:11:10',\n",
       " '689288302-~2-~pcozende-~EMEAR-ORCH-ACI-~2020-06-15 10:21:57',\n",
       " '689286274-~3-~onaguib-~EMEAR-ORCH-ACI-~2020-06-15 10:37:02',\n",
       " '689288525-~2-~anirukas-~GCE-ACI-Solutions-~2020-06-15 10:38:24',\n",
       " '689288521-~1-~prpratee-~APT-ACI-SOLUTIONS2-~2020-06-15 10:38:42',\n",
       " '689277718-~2-~visgupt2-~GCE-ACI-Solutions-~2020-06-15 10:38:58',\n",
       " '689288363-~3-~oalhadee-~EMEAR-ORCH-ACI-~2020-06-15 10:43:11',\n",
       " '689288701-~3-~lowtouch-~VIRTUAL-~2020-06-15 11:05:15',\n",
       " '689288463-~3-~deseth2-~GCE-ACI-Solutions-~2020-06-15 10:21:30',\n",
       " '689288542-~3-~yalamad-~AMM-ACI-~2020-06-15 11:15:05',\n",
       " '689288485-~3-~mobeidat-~AMM-ACI-~2020-06-15 11:17:39',\n",
       " '689288830-~3-~lowtouch-~VIRTUAL-~2020-06-15 11:29:34',\n",
       " '689288783-~3-~vlvenkat-~GCE-ACI-Solutions-~2020-06-15 11:32:01',\n",
       " '689288824-~3-~njaved-~UNASSIGNED-~2020-06-15 11:35:25',\n",
       " '689288836-~3-~bharatkc-~GCE-ACI-Solutions-~2020-06-15 11:39:27',\n",
       " '689288813-~3-~joecheva-~EMEAR-ORCH-ACI-~2020-06-15 11:40:42',\n",
       " '689288701-~3-~akhraisa-~AMM-ACI-~2020-06-15 11:42:49',\n",
       " '689288936-~3-~kshcheku-~EMEAR-ORCH-ACI-~2020-06-15 11:51:28',\n",
       " '689288880-~3-~birai-~GCE-ACI-Solutions-~2020-06-15 11:54:25',\n",
       " '689288953-~3-~vlvenkat-~GCE-ACI-Solutions-~2020-06-15 11:56:41']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "date = datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
    "######Function to remove a speicifc date accept events ######\n",
    "def RemoveAcceptEventByDateFromFile(date,AcceptEvents):\n",
    "    if not AcceptEvents:\n",
    "        return {}\n",
    "    ######Need to deep copy the list ######\n",
    "    RemovedDateAcceptEvents = copy.deepcopy(AcceptEvents)\n",
    "    for year,events in AcceptEvents.items():\n",
    "        for index,event in enumerate(AcceptEvents[year][::-1]):\n",
    "            caseno,severity,ccoid,workgroup,casetime = event.split('-~')\n",
    "            if parser.parse(casetime).strftime(\"%Y-%m-%d\") == date:\n",
    "                #print(\"Removing AcceptEvents {} - {} \".format(date,event.strip()))\n",
    "                RemovedDateAcceptEvents[year].pop(len(AcceptEvents[year])-index-1)\n",
    "            if parser.parse(casetime) < parser.parse(date):\n",
    "                break\n",
    "    return RemovedDateAcceptEvents\n",
    "\n",
    "date = (datetime.datetime.today() - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "RemovedDateAcceptEvents = RemoveAcceptEventByDateFromFile(date,AcceptEvents_by_year)\n",
    "RemovedDateAcceptEvents[2020][-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['689287679-~3-~mapedro-~EMEAR-ORCH-ACI-~2020-06-15 08:45:45',\n",
       " '689287922-~3-~lowtouch-~VIRTUAL-~2020-06-15 08:52:34',\n",
       " '689287944-~2-~mapedro-~EMEAR-ORCH-ACI-~2020-06-15 08:59:53',\n",
       " '689284852-~3-~knagavol-~GCE-ACI-Solutions-~2020-06-15 09:03:51',\n",
       " '689287895-~3-~pcozende-~EMEAR-ORCH-ACI-~2020-06-15 09:11:06',\n",
       " '689286199-~3-~birai-~GCE-ACI-Solutions-~2020-06-15 09:12:44',\n",
       " '689287922-~3-~rbushnaq-~AMM-ACI-~2020-06-15 09:27:44',\n",
       " '689058098-~3-~anirukas-~GCE-ACI-Solutions-~2020-06-15 09:27:46',\n",
       " '689287943-~3-~halhadda-~AMM-ACI-~2020-06-15 09:36:09',\n",
       " '689287969-~3-~dgomezbe-~EMEAR-ORCH-ACI-~2020-06-15 09:36:47',\n",
       " '689288363-~3-~lowtouch-~VIRTUAL-~2020-06-15 09:56:17',\n",
       " '689288388-~3-~amponnus-~CA-MANAGER-~2020-06-15 10:02:19',\n",
       " '689285538-~3-~apubillo-~EMEAR-ORCH-ACI-~2020-06-15 10:11:10',\n",
       " '689288302-~2-~pcozende-~EMEAR-ORCH-ACI-~2020-06-15 10:21:57',\n",
       " '689286274-~3-~onaguib-~EMEAR-ORCH-ACI-~2020-06-15 10:37:02',\n",
       " '689288525-~2-~anirukas-~GCE-ACI-Solutions-~2020-06-15 10:38:24',\n",
       " '689288521-~1-~prpratee-~APT-ACI-SOLUTIONS2-~2020-06-15 10:38:42',\n",
       " '689277718-~2-~visgupt2-~GCE-ACI-Solutions-~2020-06-15 10:38:58',\n",
       " '689288363-~3-~oalhadee-~EMEAR-ORCH-ACI-~2020-06-15 10:43:11',\n",
       " '689288701-~3-~lowtouch-~VIRTUAL-~2020-06-15 11:05:15',\n",
       " '689288463-~3-~deseth2-~GCE-ACI-Solutions-~2020-06-15 10:21:30',\n",
       " '689288542-~3-~yalamad-~AMM-ACI-~2020-06-15 11:15:05',\n",
       " '689288485-~3-~mobeidat-~AMM-ACI-~2020-06-15 11:17:39',\n",
       " '689288830-~3-~lowtouch-~VIRTUAL-~2020-06-15 11:29:34',\n",
       " '689288783-~3-~vlvenkat-~GCE-ACI-Solutions-~2020-06-15 11:32:01',\n",
       " '689288824-~3-~njaved-~UNASSIGNED-~2020-06-15 11:35:25',\n",
       " '689288836-~3-~bharatkc-~GCE-ACI-Solutions-~2020-06-15 11:39:27',\n",
       " '689288813-~3-~joecheva-~EMEAR-ORCH-ACI-~2020-06-15 11:40:42',\n",
       " '689288701-~3-~akhraisa-~AMM-ACI-~2020-06-15 11:42:49',\n",
       " '689288936-~3-~kshcheku-~EMEAR-ORCH-ACI-~2020-06-15 11:51:28',\n",
       " '689288880-~3-~birai-~GCE-ACI-Solutions-~2020-06-15 11:54:25',\n",
       " '689288953-~3-~vlvenkat-~GCE-ACI-Solutions-~2020-06-15 11:56:41',\n",
       " '689304293-~1-~siddhp-~UC_WORKGROUP-~2020-06-17 00:07:02',\n",
       " '688563606-~3-~trepala-~US-ACI-SOL-WEST-~2020-06-17 00:07:14',\n",
       " '689302095-~3-~deepaky-~APT-ACI-SOLUTIONS2-~2020-06-17 00:07:34',\n",
       " '689299756-~2-~siddhp-~APT-ACI-SOLUTIONS-~2020-06-17 00:10:05',\n",
       " '689304293-~1-~minkwong-~UC_WORKGROUP-~2020-06-17 00:09:14',\n",
       " '689261722-~3-~maveer-~UC_WORKGROUP-~2020-06-17 00:25:45',\n",
       " '689091789-~2-~debabbar-~FTS_WORKGROUP-~2020-06-17 00:28:08',\n",
       " '689292729-~1-~hethakur-~UC_WORKGROUP-~2020-06-17 00:31:29']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AddEventList = AcceptEventInOrderList\n",
    "\n",
    "######Function to add a speicifc date inqueue inorder events ######\n",
    "def AddAcceptEventByDateFromFile(date, AddList, AcceptEvents):\n",
    "    if not AcceptEvents:\n",
    "        AcceptEvents = {}\n",
    "    if parser.parse(date).year not in AcceptEvents.keys():\n",
    "        AcceptEvents[parser.parse(date).year] = []\n",
    "    ######Need to deep copy the list ######\n",
    "    AddedDateAcceptEvents = copy.deepcopy(AcceptEvents)\n",
    "    insert_index = len(AcceptEvents)\n",
    "    for year, events in AcceptEvents.items():\n",
    "        for index,event in enumerate(AcceptEvents[year][::-1]):\n",
    "            caseno,severity,ccoid,workgroup, casetime = event.split('-~')\n",
    "            #print(event.strip())\n",
    "            if parser.parse(casetime).date() < parser.parse(date).date():\n",
    "                #print(\"Insert Index Found {}-{} {}\".format(parser.parse(casetime).date(),parser.parse(date).date(),insert_index))\n",
    "                insert_index = index\n",
    "                break\n",
    "        insert_idex = len(AddedDateAcceptEvents[year])-insert_index\n",
    "        #print(\"Insert Index {}\".format(insert_idex))\n",
    "        #print(AcceptEvents[year][insert_idex])\n",
    "        \n",
    "        for event in AddList[::]:\n",
    "            #print(\"Adding AcceptEvent {} - {} at {}\".format(date, event,insert_index))\n",
    "            AddedDateAcceptEvents[year].insert(len(AddedDateAcceptEvents[year])-insert_index,event)\n",
    "    return AddedDateAcceptEvents\n",
    "\n",
    "date = (datetime.datetime.today() + datetime.timedelta(days=-1)).strftime(\"%Y-%m-%d\")\n",
    "AddedDateAcceptEvents = AddAcceptEventByDateFromFile(date,AddEventList,RemovedDateAcceptEvents)\n",
    "AddedDateAcceptEvents[2020][-40:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
